{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e953c0-7ea9-4c6e-9234-8310b5e435c2",
   "metadata": {},
   "source": [
    "# Week 4 - Practice Exercises\n",
    "\n",
    "This notebook contains a range of practice exercises that demonstrate how data transformation and geoprocessing operations can be sequenced to complete a task. Here, we have a vector dataset of polygon geometries which correspond to areas in Fiji impacted by Tropical Cyclone Yasa. These geometries were digitised by the <a href=\"https://emergency.copernicus.eu/mapping/list-of-activations-rapid\" target=\"_blank\">European Commission Copernicus Emergency Management Service (EMS) - Rapid Mapping Activations</a>. \n",
    "\n",
    "We also have a post tropical cyclone event NDVI image computed from Sentinel-2 satellite data. We wish to i) compute the average NDVI value of pixels inside each polygon and ii) generate a sample of polygons where there was no observed disaster impact and compute the average NDVI values for these no-impact polygons. \n",
    "\n",
    "To compute the average NDVI values for all pixels that intersect a polygon geometry we will use a raster-vector operation called **zonal statistics**. \n",
    "\n",
    "However, before we get to the stage where we can compute zonal statistics we need to pre-process our polygon geometries. This involves reprojecting the geometries to match the coordinate reference system of the raster data and performing a range of <a href=\"https://geopandas.org/en/stable/docs/user_guide/geometric_manipulations.html\" target=\"_blank\">**geometry operations**</a> to generate a sample of no-impact polygons. <a href=\"https://py.geocompx.org/04-geometry-operations\" target=\"_blank\">**Geometry operations**</a> involve manipulating the shape of geometric objects. \n",
    "\n",
    "Geometry operations that manipulate shapes include computing the centroids of polygons (transforming a polygon object to a point), buffering a geometry (increasing the size of a geometry), computing the intersection between two geometries (reducing the area, length, or size of a geometry based on its relationship with another geometry), or combining two geometries by computing their union. It is important to be able to look up different geometry operations in the <a href=\"https://geopandas.org/en/stable/docs/user_guide/geometric_manipulations.html\" target=\"_blank\">GeoPandas</a> documentation. Geometry operations are important parts of data transformation and geoprocessing workflows where raw or input spatial data is converted into a format for subsequent tasks such as statistical analysis, machine learning, or data visualisation.  \n",
    "\n",
    "## Setup\n",
    "\n",
    "### Run the labs\n",
    "\n",
    "You can run the labs locally on your machine or you can use cloud environments provided by Google Colab. **If you're working with Google Colab be aware that your sessions are temporary and you'll need to take care to save, backup, and download your work.**\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/geog3300-agri3003/coursebook/blob/main/docs/notebooks/week-4_practice.ipynb\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "### Download data\n",
    "\n",
    "If you need to download the data for this lab, run the following code snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d5905-1c8d-4e05-8eac-0411e67d301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "if \"data_lab-4_practice\" not in os.listdir(os.getcwd()):\n",
    "    subprocess.run('wget \"https://github.com/geog3300-agri3003/lab-data/raw/main/data_lab-4_practice.zip\"', shell=True, capture_output=True, text=True)\n",
    "    subprocess.run('unzip \"data_lab-4_practice.zip\"', shell=True, capture_output=True, text=True)\n",
    "    if \"data_lab-4_practice\" not in os.listdir(os.getcwd()):\n",
    "        print(\"Has a directory called data_lab-4_practice been downloaded and placed in your working directory? If not, try re-executing this code chunk\")\n",
    "    else:\n",
    "        print(\"Data download OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f5c88-bded-417d-a4b1-a68de6f56da4",
   "metadata": {},
   "source": [
    "### Working in Colab\n",
    "\n",
    "If you're working in Google Colab, you'll need to install the required packages that don't come with the colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa7e5c7-5f68-4c90-a723-59f27eee63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install xarray[complete]\n",
    "    !pip install rioxarray\n",
    "    !pip install mapclassify\n",
    "    !pip install rasterio\n",
    "    !pip install rasterstats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b7cd6-c430-4698-8ee7-018fe9914fb6",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5367087-be25-44be-b46f-68416340f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import pprint \n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "# setup renderer\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"jupyterlab\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1d1bf-37d5-4a5b-a86e-cce96e4a9edc",
   "metadata": {},
   "source": [
    "## Geometry operations\n",
    "\n",
    "Let's load the vector polygon data that delineates the observed disaster impact following Tropical Cyclone Yasa and visualise it to see it's structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733215f9-0cb9-433d-a446-cef6124fa2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_path = os.path.join(os.getcwd(), \"data_lab-4_practice\", \"EMSR489_AOI07_GRA_PRODUCT_observedEventA_r1_v1.shp\")\n",
    "obs_event_gdf = gpd.read_file(obs_event_path)\n",
    "obs_event_gdf.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef46d31b-abde-4902-b56f-5b24eb57b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c842b-eb1f-4ae9-9b48-9c2983023021",
   "metadata": {},
   "source": [
    "We're going to be using these geometries in a **zonal statistics** operation. This is a raster-vector operation where we compute summary statistics for all raster pixels that intersect with a polygon geometry. Here, we'll use a Sentinel-2 NDVI image captured just after Tropical Cyclone Yasa impacted this region. However, this satellite image has the projection system `EPSG:32760`. \n",
    "\n",
    "**Can you use the GeoPandas `GeoDataFrame` method `to_crs()` to convert `obs_event_gdf` to `EPSG:32760`? Assign the variable name `obs_event_gdf_32760` to the reprojected `GeoDataFrame`.**\n",
    "\n",
    "The GeoPandas docs for reprojection are <a href=\"https://geopandas.org/en/stable/docs/user_guide/projections.html#re-projecting\" target=\"_blank\">here</a> if you want to look up how to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e2d3e-99f0-430c-8ba9-0fc4be6a7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dafa1bf-6061-4908-966e-798b668070b2",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "\n",
    "```python\n",
    "obs_event_gdf_32760 = obs_event_gdf.to_crs(\"EPSG:32760\")\n",
    "```\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><b>Why do we need the polygon geometries and raster data to be in the same projection system for zonal statistics operations?</b></summary>\n",
    "\n",
    "To ensure the polygon geometries are intersected with raster pixels that correspond to the same location on the Earth's land surface. \n",
    "\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "Our task is to compute summary statistics for each of the polygon geometries that delineate an area impacted by the tropical cyclone event. However, for comparison, we'd also like to generate some sample polygons of areas without a visible impact. We can do this through a sequence of geoprocessing operations that manipulate geometry objects. \n",
    "\n",
    "The first step is to combine our `GeoDataFrame` of many polygon objects into a single multipolygon object. We can do this using the <a href=\"https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.unary_union.html\" target=\"_blank\">`unary_union` property</a> of a `GeoSeries` (i.e. the `geometry` column in a `GeoDataFrame`). The `unary_union` computes the union of many polygon objects. The is a geometry aggregation operation, combining many geometry objects into one. \n",
    "\n",
    "Below is a quick visualisation of a multipolygon object. We can use multipolygon objects in a number of ways in our programs. For example, we could use multipolygon objects to conveniently represent a country consisting of many islands as a single feature. However, here we'll use them as they help simplify some of the geometry operations we wish to perform in subsequent tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8452d-8507-4875-b087-c1296d94413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "shapely.geometry.MultiPolygon([\n",
    "    shapely.geometry.Polygon([(0.8,0.8), (0.9,1.0), (1.0,0.9), (0.9,0.9), (0.8,0.8)]), \n",
    "    shapely.geometry.Polygon([(0.0,0.1), (0.2,0.4), (0.4,0.3), (0.0,0.0), (0.0,0.1)])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb9faa-8b2b-441c-a85e-39137523a434",
   "metadata": {},
   "source": [
    "If we print the multipolygon object, you can see the geometries are represented as a nested collection of polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a0f2f-1f1b-4d61-b660-5eb14d37dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    shapely.geometry.MultiPolygon([\n",
    "        shapely.geometry.Polygon([(0.8,0.8), (0.9,1.0), (1.0,0.9), (0.9,0.9), (0.8,0.8)]), \n",
    "        shapely.geometry.Polygon([(0.0,0.1), (0.2,0.4), (0.4,0.3), (0.0,0.0), (0.0,0.1)])\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3ce0c-c724-4095-8abb-61b246d9e199",
   "metadata": {},
   "source": [
    "Let's quickly inspect the structure of our `GeoDataFrame` with each polygon geometry on its own row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bbe188-2889-47fc-bba9-a29996550ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_gdf_32760.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd44c5a-4613-4d96-992d-f702f100e006",
   "metadata": {},
   "source": [
    "Now, let's compute the `unary_union` of the `geometry` column. It should return to us a `GeoSeries` with one element (a multipolygon object that has aggregated all the polygons in our `GeoDataFrame` into a single feature). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a67f2-1c6a-4d2f-85a1-d5ff1725cab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_gdf_union = gpd.GeoSeries(obs_event_gdf_32760[\"geometry\"].unary_union).set_crs(\"EPSG:32760\")\n",
    "obs_event_gdf_union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e016c7-576e-47ea-b2fb-f53390077149",
   "metadata": {},
   "source": [
    "Now we have combined our polygons into a single multipolygon object, we can use the <a href=\"https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.buffer.html\" target=\"\">buffer operation</a> to expand the geometries by a specified distance to cover areas outside the locations impacted by Tropical Cyclone Yasa. \n",
    "\n",
    "**Can you apply a 100 m buffer to the multipolygon object referenced by `obs_event_gdf_union` and reference it with the variable name `obs_event_gdf_buffer`?**\n",
    "\n",
    "**Hint: use the GeoPandas docs for the buffer operation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0cf68-fe94-457e-81cb-a7e59d9c7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7cf050-207c-41ab-8534-e02f81cbe830",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "\n",
    "```python\n",
    "obs_event_gdf_buffer = obs_event_gdf_union.buffer(100)\n",
    "```\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "Next, we'll need to set the CRS for the buffered geometries back to `EPSG:32760`. In the map below, areas where disaster impact following the tropical cyclone was observed are coloured red and adjacent areas where not disaster impact was observed are coloured blue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9716c747-8ecf-4542-a8d6-70214c4584b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_gdf_buffer = obs_event_gdf_buffer.set_crs(\"EPSG:32760\")\n",
    "m = obs_event_gdf_buffer.explore()\n",
    "obs_event_gdf_32760.explore(m=m, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5206a20c-e029-4ff0-a888-104158aea18d",
   "metadata": {},
   "source": [
    "We want to use this data as sample polygons where there was no disaster impact. Therefore, we need to remove the interior areas of the polygons which correspond to the locations where disaster impact on the land surface was recorded (these are the red polygons on the map above). We can do this using the GeoPandas <a href=\"https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.difference.html\" target=\"_blank\">`difference()` method</a>; this returns to us geometries of all the locations in one geometry that are not in another geometry.\n",
    "\n",
    "![](https://github.com/data-analysis-3300-3003/figs/raw/main/week-4-difference.jpg)\n",
    "\n",
    "**Can you use the `difference()` method of the `GeoDataFrame` `obs_event_gdf_buffer` to remove locations where a disaster event impact was recorded (represented in the `GeoDataFrame` `obs_event_gdf_union`)?**\n",
    "\n",
    "Assign the result to the variable name `obs_event_no_impact`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef613f75-e7e9-4e05-afe4-2a0bce60b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e043ff89-d944-4ae1-9eab-d75ebd32ef67",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "\n",
    "```python\n",
    "obs_event_no_impact = obs_event_gdf_buffer.difference(obs_event_gdf_union)\n",
    "```\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "Let's check the result looks sensible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba7e40-9992-418a-ab26-01a648457df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_no_impact.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbdf623-bb48-4610-ac99-af7b314652fb",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Why did we compute the buffer and difference operations on a multipolygon (created via the <code>unary_union</code>) instead of using a <code>GeoDataFrame</code> of many polygon geometries?</b></summary>\n",
    "    \n",
    "If we computed the buffer operation on many separate polygons, we'd return many larger buffered polygons which would be overlapping in places. This, in itself, is not necessarily an issue. But, we use the buffered polygons in a <code>difference()</code> operation to remove interior areas where disaster impacts occurred. The <code>difference()</code> operation works on a row-by-row basis (i.e. the geometry in row 1 of <code>GeoDataFrame</code> A is compared to the geometry of row 1 in <code>GeoDataFrame</code> B - the geometry in row 1 of <code>GeoDataFrame</code> A is NOT compared to the geometry of row 2 in <code>GeoDataFrame</code> B). This is problematic if the disaster impact area of represented by the geometry in row 2 in <code>GeoDataFrame</code> B overlaps with the geometry in row 1 of <code>GeoDataFrame</code> A. In this case we would not be able to fully remove areas where disaster impact was recorded. However, by comparing two multipolygon objects on a row-by-row basis (there is just one row in <code>GeoDataFrame</code> A and B) we can ensure all areas where disaster impact was recorded are removed. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be36235-554c-40c6-ac86-2f6ff25d7e1f",
   "metadata": {},
   "source": [
    "Now, let's convert the `GeoSeries` multipolygon object into a `GeoSeries` of many individual polygon objects using the <a href=\"https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.explode.html\" target=\"_blank\">`explode` method</a>. This operation takes each of the polygons that comprise the composite multipolygon feature and returns them as a `GeoSeries` of separate polygon features. \n",
    "\n",
    "<details>\n",
    "    <summary><b>Why have we used the <code>explode</code> method to split a multipolygon representation of areas not impacted by the disaster event into separate polygons?</b></summary>\n",
    "We will use these polygons to capture the NDVI signal of areas not impacted by Tropical Cyclone Yasa. If we compute the mean NDVI value for all pixels that intersect with the multipolygon object we'll get a single value for the entire region of interest. This single mean NDVI value might mask lots of spatial variation in the NDVI signal of not impacted areas; computing the NDVI value for many smaller polygons can provide information on variation in the NDVI values of not impacted areas across the scene. Also, if we have many geometries representing not impacted areas which we can compute mean NDVI values for, we can compare these NDVI values with the mean NDVI of nearby polygons where there was a disaster impact. This might give us a more accurate indication of the impact of the Tropical Cyclone on vegetation cover as we're more likely to be comparing similar land covers or exposure to cyclone event.  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582e2449-96f2-4df5-9e2c-254e89ca22c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_no_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab46410d-3dbb-4cf6-a58d-0e9b8086beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_no_impact = obs_event_no_impact.explode(ignore_index=True)\n",
    "obs_event_no_impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bad370-ed86-4078-962b-2e029414858c",
   "metadata": {},
   "source": [
    "Finally, let's do some `GeoDataFrame` subsetting and concatenation to combine polygons corresponding to disaster event impact with the no impact polygons.\n",
    "\n",
    "First, let's make the `obs_event_no_impact` `GeoSeries` a `GeoDataFrame` with an `obj_desc` column to match the observed disaster event impact `GeoDataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c8b24-fc05-4a87-a4d9-2c5e86285793",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_no_impact_id = pd.DataFrame({\"obj_desc\": [\"no impact\" for x in range(0,35)]})\n",
    "obs_event_no_impact = gpd.GeoDataFrame(obs_event_no_impact_id, geometry=obs_event_no_impact, crs=\"EPSG:32760\")\n",
    "obs_event_no_impact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ec6f30-fb71-41a3-a456-241b32d0fd06",
   "metadata": {},
   "source": [
    "Next, let's just get the `obj_desc` and the `geometry` columns from `obs_event_gdf_32760` and concatenate the two `GeoDataFrames` (i.e. stack them on top of each other row wise).\n",
    "\n",
    "<details>\n",
    "    <summary><b>Why are we subsetting out the the <code>obj_desc</code> and <code>geometry</code> columns?</b></summary>\n",
    "We are subsetting these two columns to match the columns in the <code>obs_event_no_impact</code> <code>GeoDataFrame</code>. This allows us to stack the <code>DataFrame</code>s on top of each other row wise with the columns matching up. \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59acd021-b7bf-4936-997a-6cbb47152b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_event_gdf_32760 = obs_event_gdf_32760.loc[:, [\"obj_desc\", \"geometry\"]]\n",
    "sample_polygons = pd.concat([obs_event_gdf_32760, obs_event_no_impact], axis=0)\n",
    "sample_polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbb541-5762-452b-b8ec-275b254cfdf3",
   "metadata": {},
   "source": [
    "## Zonal stats\n",
    "\n",
    "We now have 269 sample polygons of locations affected by Tropical Cyclone Yasa and those without visible impacts. We want to compute the average NDVI values across all pixels that intersect each polygon. This is a **zonal statistics operation**. \n",
    "\n",
    "We can use the `zonal_stats()` function from the <a href=\"https://pythonhosted.org/rasterstats/manual.html#statistics\" target=\"_blank\">rasterstats package</a> to perform zonal statistics in Python. \n",
    "\n",
    "The `zonal_stats()` function takes in vector data of geometries that zonal statistics are computed for as its first argument (or a file path to a vector file), the path to a raster dataset (i.e. a GeoTIFF file) as its second argument, and optionally a list of statistics to compute to the `stats` argument. You can find the full list of parameters for the `zonal_stats()` function in the package documentation.\n",
    "\n",
    "**Can you look up what the `all_touched` parameter of the `zonal_stats()` function is used to specify in the <a href=\"https://pythonhosted.org/rasterstats/manual.html#rasterization-strategy\" target=\"_blank\">rasterstats docs</a>?**\n",
    "\n",
    "We have a GeoTIFF file of NDVI values computed from a Sentinel-2 image captured just after Tropical Cyclone Yasa at the file path `os.path.join(os.getcwd(), \"data_lab-4_practice\", \"ndvi_post_yasa_int16.tif\")`.\n",
    "\n",
    "Let's use it to compute the average NDVI value for each of the polygons in the `GeoDataFrame` `sample_polygons`. `zonal_stats` returns to us a dictionary object for each polygon with the summary statistic label as a key and the computed statistic as the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627cd68-fbbb-4897-90d9-b175c925ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_zonal_stats = zonal_stats(sample_polygons, os.path.join(os.getcwd(), \"data_lab-4_practice\", \"ndvi_post_yasa_int16.tif\"), stats=[\"mean\"], all_touched=True)\n",
    "pprint.pprint(f\"print the mean NDVI for the first 10 polygons: {ndvi_zonal_stats[0:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4c473-333d-4913-a603-a323dff27a92",
   "metadata": {},
   "source": [
    "We can convert the list of dictionary objects into a `DataFrame` using the `DataFrame` constructor function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39afb555-f183-4970-a381-f7fd33b380f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_stats_df = pd.DataFrame(ndvi_zonal_stats)\n",
    "zonal_stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595b34dd-b673-4c16-bc43-c9279c73b350",
   "metadata": {},
   "source": [
    "The NDVI data is in integer format and has been scaled by 1000 (it is cheaper to store integer data than floating point data). However, NDVI values should be between -1 and 1. Let's fix this by dividing the NDVI values by 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a420e-213e-49ca-ad32-78a5a397e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_stats_df[\"mean\"] = zonal_stats_df[\"mean\"] / 1000\n",
    "zonal_stats_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb77294-835a-4927-8a81-0e0b35623aaa",
   "metadata": {},
   "source": [
    "Finally, we can add the column of `mean` NDVI values for each polygon back to our `GeoDataFrame`. This means we can display our polygons and map the fill colour of each polygon to its mean NDVI value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06214dfb-3493-4a16-851e-f320d4b44c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_polygons[\"ndvi\"] = zonal_stats_df.loc[:, [\"mean\"]]\n",
    "sample_polygons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f296f0d-3f2f-4089-864b-9a8319f7eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_polygons.explore(column=\"ndvi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c53e2e-2b5d-479e-acac-3d21c0c9d1ae",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Can you identify some limitations of this approach to generating a sample of areas not impacted by Tropical Cyclone Yasa?</b></summary>\n",
    "    \n",
    "<ul>\n",
    "    <li>We used the areas directly adjacent to observed impact as our no impact sample. If there is error in how the disaster impact was delineated, it is likely that a disaster impact signal might leak into zones we've labelled as not impacted. A better strategy might be to use sample locations a specified distance from an observed impact.</li>\n",
    "    <li>There could be differences in NDVI across land covers. If there are different land covers in the impacted area and not impacted area, we could be assigning a difference in NDVI due to land cover differences to disaster impact.</li>\n",
    "    <li>We could use difference NDVI images. Comparing the change in NDVI before and after disaster event in areas where a disaster impact was observed to areas where it was not.</li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><b>What data transformation and geoprocessing operations could you deploy if you just wanted to focus on the disaster impacts to croplands?</b></summary>\n",
    "    \n",
    "You could obtain a land cover map with a cropland class and mask all pixels that are not classified as cropland before computing zonal stats (i.e. set their values <code>NaN</code>).\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
