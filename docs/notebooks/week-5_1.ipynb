{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd3be33-1a3c-4fd3-a3e7-cd82ed8309fa",
   "metadata": {},
   "source": [
    "# Machine learning 1\n",
    "\n",
    "This lab will provide an introduction to key machine learning concepts and also demonstrate how you can use <a href=\"https://scikit-learn.org/stable/\" target=\"_blank\">Scikit-learn</a> to implement machine learning workflows in Python. \n",
    "\n",
    "The focus of this lab will be on supervised machine learning. This lab will develop a machine learning workflow that classifies the crop type of fields in India using spectral reflectance values recorded by the Sentinel-2 satellite. It is based on the AgriFieldNet Competition Dataset <a href=\"https://mlhub.earth/data/ref_agrifieldnet_competition_v1\" target=\"_blank\">(Radiant Earth Foundation and IDinsight, 2022)</a> which has been published to encourage people to develop machine learning models that classify a field's crop type from satellite images. \n",
    "\n",
    "The dataset includes spectral reflectance values, crop type labels, field id, and geometry for the field's location from cropping landscapes in the Indian States of Odisha, Uttar Pradesh, Bihar, and Rajasthan. The field boundaries and crop type labels were captured by data collectors from IDinsights Data on Demand team and the satellite image preparation was undertaken by the Radiant Earth Foundation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59abba0f-10c8-4538-9377-d8e086d9eae2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Run the labs\n",
    "\n",
    "You can run the labs locally on your machine or you can use cloud environments provided by Google Colab. **If you're working with Google Colab be aware that your sessions are temporary and you'll need to take care to save, backup, and download your work.**\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/geog3300-agri3003/coursebook/blob/main/docs/notebooks/week-5_1.ipynb\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "### Download data\n",
    "\n",
    "If you need to download the date for this lab, run the following code snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495b41e2-b195-4c5f-a032-f0aecf85e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "if \"data_lab-5\" not in os.listdir(os.getcwd()):\n",
    "    subprocess.run('wget \"https://github.com/geog3300-agri3003/lab-data/raw/main/data_lab-5.zip\"', shell=True, capture_output=True, text=True)\n",
    "    subprocess.run('unzip \"data_lab-5.zip\"', shell=True, capture_output=True, text=True)\n",
    "    if \"data_lab-5\" not in os.listdir(os.getcwd()):\n",
    "        print(\"Has a directory called data_lab-5 been downloaded and placed in your working directory? If not, try re-executing this code chunk\")\n",
    "    else:\n",
    "        print(\"Data download OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960b7fc-7acc-41c4-93e0-6ed25320ee5e",
   "metadata": {},
   "source": [
    "### Working in Colab\n",
    "\n",
    "If you're working in Google Colab, you'll need to install the required packages that don't come with the colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e8dc92-ae80-4a7f-93c8-2351eca4c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install rioxarray\n",
    "    !pip install mapclassify\n",
    "    !pip install rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1339bf-196c-48f3-8fa7-e27526b91e5a",
   "metadata": {},
   "source": [
    "## Machine learning\n",
    "\n",
    "Machine learning is the process of learning from data to make predictions. **Supervised** machine learning models are trained to predict an outcome based on input data (predictors or features). The model is trained to minimise the error in predictions using a training set where both the outcome labels and input data are known. If the outcome is categorical (e.g. land cover type, cloud / no-cloud) then it is a **classification** machine learning task and if the outcome is numeric (e.g. crop yield, temperature) then it is a **regression** machine learning task. \n",
    "\n",
    "There are also **unsupervised** machine learning tasks where there are no known outcomes prior to model training. Unsupervised machine learning models typically cluster datasets with similar data points assigned to the same cluster or group. \n",
    "\n",
    "Please watch this introduction to machine learning video from Climate Change AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e212130-74f7-4106-92a0-ee7768d5f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "'<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/mc9QG2R-rf4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce31636-383b-4b15-864f-c654a05314c8",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/\" target=\"_blank\">Scikit-learn</a> is an open-source machine learning package for Python. It provides a range of tools for preprocessing datasets for machine learning, training machine learning models, evaluating model performance, and using a trained model to make predictions. A range of supervised and unsupervised machine learning algorithms can be used with Scikit-learn. \n",
    "\n",
    "### Task\n",
    "\n",
    "The focus of this lab will be on supervised machine learning. This lab will develop a machine learning workflow that classifies the crop type of fields in India using spectral reflectance values recorded by the Sentinel-2 satellite. It is based on the AgriFieldNet Competition Dataset <a href=\"https://mlhub.earth/data/ref_agrifieldnet_competition_v1\" target=\"_blank\">(Radiant Earth Foundation and IDinsight, 2022)</a> which has been published to encourage people to develop machine learning models that classify a field's crop type from satellite images. \n",
    "\n",
    "The dataset includes spectral reflectance values, crop type labels, field id, and geometry for the field's location from cropping landscapes in the Indian States of Odisha, Uttar Pradesh, Bihar, and Rajasthan. The field boundaries and crop type labels were captured by data collectors from IDinsights Data on Demand team and the satellite image preparation was undertaken by the Radiant Earth Foundation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41935c6b-3883-4dff-bc45-9af06648e82e",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6dc913-db97-4dcb-b77a-47fb9601d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import tree\n",
    "\n",
    "# setup renderer\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"jupyterlab\"\n",
    "\n",
    "rng = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1157c13-9fc5-4f7b-9b29-e48891ba25a5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee306f-772f-4b78-ba03-8a5430ab606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'data_lab-5', 'agrifieldnet_processed_adm4.geojson')\n",
    "gdf = gpd.read_file(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8a7ca-a21f-42e0-93ac-a4db6bcdb616",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "\n",
    "Often, after sourcing data, the first task in a machine learning workflow is data preprocessing - transforming the raw data into a format ready for model training or making predictions. These tasks are often referred to as feature engineering - the process of engineering or creating features or predictor variables. \n",
    "\n",
    "Let's inspect the data. We can see it is a `GeoDataFrame` with columns corresponding to the `field_id`, `labels` (crop type identifier), spectral reflectance in several wavebands (`B*`) and `ndvi`, the `village` where the field is located in India, and `geometry` `POINT` object for the field centroid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88163f5-6459-44cc-81d2-7e763fdbda0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The data is of type: {type(gdf)}\")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a768a-5579-49ba-8872-4a5cae1ee900",
   "metadata": {},
   "source": [
    "Based on the dataset's documentation the below is the mapping between numeric values and crop types in the labels dataset. \n",
    "\n",
    "* 1 - Wheat\n",
    "* 2 - Mustard\n",
    "* 3 - Lentil\n",
    "* 4 - No crop/Fallow\n",
    "* 5 - Green pea\n",
    "* 6 - Sugarcane\n",
    "* 8 - Garlic\n",
    "* 9 - Maize\n",
    "* 13 - Gram\n",
    "* 14 - Coriander\n",
    "* 15 - Potato\n",
    "* 16 - Bersem\n",
    "* 36 - Rice\n",
    "\n",
    "Let's explore how many examples we have of different crop types. We can see that our dataset is dominated by wheat, mustard, and no crop / fallow labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ed537-196f-4d5b-9d89-aaaa5f7a7b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make labels categorical for bar plot\n",
    "class_mappings = {\n",
    "    \"1\": \"Wheat\",\n",
    "    \"2\": \"Mustard\",\n",
    "    \"3\": \"Lentil\",\n",
    "    \"4\": \"Fallow\",\n",
    "    \"5\": \"Green pea\",\n",
    "    \"6\": \"Sugarcane\",\n",
    "    \"8\": \"Garlic\",\n",
    "    \"9\": \"Maize\",\n",
    "    \"13\": \"Gram\",\n",
    "    \"14\": \"Coriander\",\n",
    "    \"15\": \"Potato\",\n",
    "    \"16\": \"Bersem\",\n",
    "    \"36\": \"Rice\"\n",
    "}\n",
    "\n",
    "gdf[\"labels_cat\"] = gdf[\"labels\"].astype(\"str\")\n",
    "gdf.replace({\"labels_cat\": class_mappings}, inplace=True)\n",
    "\n",
    "gdf.groupby(\"labels_cat\").count().loc[:, \"field_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335fa4b-105d-41e8-bc3f-348789c86397",
   "metadata": {},
   "source": [
    "We can also explore the spatial distribution of the data. Hover over the points on the map with your cursor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f6ee91-1f0f-4622-8e96-3a229e48bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.explore(\"labels_cat\", tiles=\"CartoDB dark_matter\", cmap=\"tab20\", categorical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c080e86b-f0a1-49d9-8b21-97ca980c9026",
   "metadata": {},
   "source": [
    "There are some final preprocessing steps required before we are ready to train a model to classify a field's crop type. \n",
    "\n",
    "Scikit-learn models expect the input data and outcomes to be `array-like`. Generally, this is in the form of NumPy `ndarray` objects. \n",
    "\n",
    "We want the input data (features or predictors) to be in a separate object to the outcomes (labels). Therefore, we'll subset the `GeoDataFrame` object and store just the predictor variables in an `array-like` object `X` and the outcomes in an object `y`. \n",
    "\n",
    "Numeric Pandas `Series` or `DataFrame` objects are `array-like` and so we can directly subset columns from the `GeoDataFrame` to create input and output objects.\n",
    "\n",
    "`X` generally has the shape `(n_samples, n_features)` where each sample is aligned along the rows dimension (or 0-axis in a rank 2 NumPy `ndarray`) and the features (or predictors) are aligned along the columns dimension (or 1-axis in a rank 2 NumPy `ndarray`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100f19c2-2c59-4813-b854-c51d07c18e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gdf.drop([\"field_id\", \"labels\", \"labels_cat\", \"index_right\", \"village\", \"geometry\"], axis=1)\n",
    "y = gdf.loc[:, \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f2e29-af64-4105-abd8-c9b961fca0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0668f46-db2e-4184-82d6-e18f314b58ae",
   "metadata": {},
   "source": [
    "For classification tasks the values in `y` should be integer and for regression tasks the values in `y` should be floating point. As crop type is a categorical variable values in `y` should be of integer data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5c270-4426-4f47-9246-29dce0dc4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad6c4f0-27c2-4c7c-a22a-160520c167ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train-test splits\n",
    "\n",
    "For supervised machine learning tasks we need to create training and test datasets. \n",
    "\n",
    "The model is trained using the training set which consists of matched features and outcomes. \n",
    "\n",
    "The model is then evaluated using the test set. A prediction is made using features in the test set and the prediction is compared with known outcomes for those features. This provides an indication of the model's performance. **It is important that the test set is independent from the training set - an important part of machine learning model development is preventing information from the test set leaking into the training set**. \n",
    "\n",
    "Scikit-learn provides a useful `train_test_split()` function which expects `X` and `y` `array-like` objects as inputs and will return 4 `array-like` objects (`X_train`, `X_test`, `y_train`, `y_test`).\n",
    "\n",
    "We can provide further arguments to `train_test_split()`:\n",
    "\n",
    "* `test_size` determines the proportion of the input data that is allocated to the test set\n",
    "* `random_state` is a seed that ensures the same random split of the data occurs each time the code is executed. This is important for reproduciblity of results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6385f217-54de-4806-99b3-faaf47644381",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=rng, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a78b2f-44ad-4dad-b042-463522ba379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the size of the training features object is {X_train.shape}\") \n",
    "print(f\"the size of the test features object is {X_test.shape}\")\n",
    "print(f\"the size of the training outcomes object is {y_train.shape}\")\n",
    "print(f\"the size of the test features object is {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81070928-5934-4d87-a9b9-b2a55d903f31",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Scikit-learn provides a range of machine learning algorithms that can be trained for different tasks (e.g. classification, regression, text, images, clustering etc.). \n",
    "\n",
    "In Scikit-learn terminology each of these algorithms is called an <a href=\"https://scikit-learn.org/stable/glossary.html#term-estimators\" target=\"_blank\">`estimator`</a> - the docs have a useful <a href=\"https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\" target=\"_blank\">interactive guide</a> to help you select the right `estimator` for your machine learning task.\n",
    "\n",
    "Each `estimator` object has a `fit()` method. The fit method expects the training data as arguments (`X_train` and `y_train`) and when called learns rules that minimise the error in predicting the outcome labels in `y_train`. This is the *learning* part of the machine learning workflow. \n",
    "\n",
    "Here, we will demonstrate how to train a tree-based machine learning model: a random forests classifier. \n",
    "\n",
    "First, we create an `estimator` object for the model. Then, we use the `estimator`'s `fit()` method to train the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf22c02-56ee-4830-b1f1-c803b0f559f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random forests classifiers\n",
    "\n",
    "Random forests models are an ensemble and tree-based model. They're a tree-based model as they consist of an ensemble of decision tree classifiers.\n",
    "\n",
    "Please read through this <a href=\"https://developers.google.com/machine-learning/decision-forests/decision-trees\" target=\"_blank\">Google Machine Learning Guide on decision trees and random forests</a>.\n",
    "\n",
    "<details>\n",
    "    <summary><b>Detailed notes on tree-based models</b></summary>\n",
    "    \n",
    "Decision tree classifiers are trained to learn rules that classify outcome labels based on input features by recursively splitting the feature space. The algorithm starts by finding the value of a feature that splits the dataset into two groups which minimise the \"impurity\" of outcome labels in each group. Then, that process is repeated by splitting each of the two groups, again to minimise the \"impurity\" of outcome labels. This process repeats until a stopping criterion is reached. The Gini index is the default metric to measure class impurity in each internal node of the tree. \n",
    "\n",
    "The class label associated with each of the terminal nodes of the tree is based on the most commonly occurring class. \n",
    "\n",
    "Individual decision tree classifiers are relatively quick to train, can learn non-linear and interactive relationships between input features and outcome labels, and are easy to visualise and interpret. \n",
    "\n",
    "However, there are limits to decision tree classifiers. They are often not the most accurate classifiers. They also have high variance; if you train a decision tree classifier on two different samples it will likely learn different relationships and generate different predictions. Large decision trees can also overfit the training data; they can learn to fully represent the structure of the training set but will not generalise well to new and unseen data.\n",
    "    \n",
    "Random forests models mitigate the limitations of a single decision tree classifier by:\n",
    "\n",
    "<b>bagging:</b> training a number (ensemble) of decision trees based on bootstrap samples of the training datasets. The average prediction from many decision tree models reduces the variance in predictions.\n",
    "\n",
    "<b>sampling features at each split:</b> when training each of the decision trees in the ensemble, a random selection of features are searched for each split within the tree. This prevents a small number of features from dominating the model, enables the model to learn using all the input features, and reduces overfitting. If there are <em>p</em> features, then often the <em>m</em> &radic;<em>p</em> are considered at each split.\n",
    "    \n",
    "<b>majority vote:</b> for classification tasks, the final predicted value from a random forest model is the most common prediction of the outcome label across all trees in the ensemble.\n",
    "      \n",
    "</details>\n",
    "<p></p>\n",
    "\n",
    "Let's create a random forest model `estimator` object using the `RandomForestClassifier()` function. We'll set the `n_estimators` parameter to 20 here; this means the random forest will consist of an ensemble of 20 decision tree classifiers. The `random_state` parameter ensures we learn the same model each time we train it on the same data; this is important for reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8efa2-6e2a-4ac1-80fd-c42d04c8913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train a random forests model\n",
    "rf = RandomForestClassifier(n_estimators=20, random_state=rng)\n",
    "rf.fit(X_train, y_train.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3cae71-ef1e-42a3-8c1e-d76776bdd1f6",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "After training a model, we need to evaluate it to assess its performance. This evaluation allows us to compare different models and get an indication of how well the model will perform when it is used on new data. \n",
    "\n",
    "After training, the model object, `rf` in this case stores rules that map input data to output (predicted) labels. In the case of a random forests model, these rules are stored and expressed as a collection of decision trees. \n",
    "\n",
    "It is important that the test data used to evaluate a model is independent of the training data; this is to ensure an unbiased estimate of model performance. \n",
    "\n",
    "There are a range of model evaluation metrics for classification tasks:\n",
    "\n",
    "* **accuracy**: the proportion of correctly classified examples. \n",
    "* **recall**: the ratio of true positives to true positives and false negatives - the ability of the classifier to capture all positive cases. $recall = \\frac{tp}{tp+fn}$.\n",
    "* **precision**: the ratio of true positives to true positives and false positives - the classifiers ability not to label something as positive when it is not. $precision = \\frac{tp}{tp+fp}$.\n",
    "* **f1-score**: the f1-score combines the recall and precision scores and takes on the range 0 to 1. $F1 = 2\\cdot\\frac{precision\\cdot{recall}}{precision+recall}$\n",
    "\n",
    "Scitkit-learn provides a `classification_report()` which can be used to generate performance metrics for each class and the model as a whole. \n",
    "\n",
    "The `classification_report()` expects known outcome labels and predicted outcome labels. To generate the predicted labels, we can use the `predict()` method of the `estimator` object and pass in input test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31c3d8-59a0-4786-a214-815987ca7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445885da-dcb4-4305-98c5-981bf5620389",
   "metadata": {},
   "source": [
    "From the classification report, we can ascertain the following:\n",
    "\n",
    "* the model's overall accuracy is 0.68 - 68% of the examples in the test set were classified correctly.\n",
    "* the model's performance is better for class labels 1 (wheat), 4 (fallow), and 9 (maize). \n",
    "* the performance metric scores for the other classes is lower. \n",
    "* the model's performance is best for classes with the most observations in the training dataset. \n",
    "* we're getting a warning indicating to us that the precision and f1-score are being set to zero in labels with no predicted samples.\n",
    "\n",
    "We can also plot a confusion matrix to see if there are patterns of confusion between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17f797-cfe6-40c4-af91-daee914ff208",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Wheat\", \n",
    "          \"Mustard\", \n",
    "          \"Lentil\", \n",
    "          \"Fallow\", \n",
    "          \"Green Pea\",\n",
    "          \"Sugarcane\",\n",
    "          \"Garlic\",\n",
    "          \"Maize\",\n",
    "          \"Gram\",\n",
    "          \"Coriander\",\n",
    "          \"Potato\",\n",
    "          \"Bersem\",\n",
    "          \"Rice\"]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(text_kw={\"fontsize\":10}, xticks_rotation=\"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d90db49-611e-4282-8dee-26c608e49490",
   "metadata": {},
   "source": [
    "From the confusion matrix, we can see:\n",
    "    \n",
    "* there is confusion between the mustard and wheat classes.\n",
    "* a large number of minitory classes as misclassified as wheat or mustard (majority classes).\n",
    "* there were no successful classifications of coriander, garlic, or bersem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be71bd3-3a37-4d39-a757-d038dad379b7",
   "metadata": {},
   "source": [
    "#### Recap quiz\n",
    "\n",
    "**Earlier, we discussed that random forests models should be more accurate than a single decision tree classifier. Can you train a decision tree classifier to test if this the case?**\n",
    "\n",
    "**The documentation for the decision tree classifier is <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\" target=\"_blank\">here</a>.**\n",
    "\n",
    "**Use `X_train`, `y_train`, `X_test`, and `y_test` for this task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c229e8f5-9384-4e18-b916-f6a231e1955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8badaaf5-cd98-4c2b-a461-c45e1d755303",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "    \n",
    "```python\n",
    "# import the tree module from scikit-learn\n",
    "from sklearn import tree\n",
    "\n",
    "# create a decision tree classifier object\n",
    "clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# test model\n",
    "y_pred_tree = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63ff4cf-7eb4-414e-8414-57ea6922c444",
   "metadata": {},
   "source": [
    "### Visualising predictions\n",
    "\n",
    "We have a `DataFrame` `X` which stores all the features before we split the data into training and test splits. We can use `X` to generate a predicted crop type label for each of our data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a1cc4-1ed9-4de9-b64e-8fd1e424013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = rf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f85753-1530-4415-82c4-44db7e8e5a60",
   "metadata": {},
   "source": [
    "We can then append the predicted crop type labels to our initial `GeoDataFrame` as a new column and visualise these predictions on a map. Hover over points on the map with your cursor to see the actual (`labels_cat`) and predicted (`predicted`) crop types for a field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1dbc56-44ee-4c4c-b7ee-ac20e052643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[\"predicted\"] = all_preds.astype(\"str\")\n",
    "gdf.replace({\"predicted\": class_mappings}, inplace=True)\n",
    "basemap = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\n",
    "attribution = \"Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community\"\n",
    "gdf.explore(column=\"predicted\", cmap=\"tab20\", categorical=True, tiles=basemap, attr=attribution, tooltip=[\"labels_cat\", \"predicted\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3d803-c0f4-4d1c-8e62-e5b02593a413",
   "metadata": {},
   "source": [
    "## Class imbalance\n",
    "\n",
    "Our training and test datasets are clearly imbalanced across the outcome class labels. The majoring of samples are of wheat (1), mustard (2), or fallow (4) classes. \n",
    "\n",
    "We can see the imbalance in our dataset using a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7647d5-953c-4254-8e48-0a5553170d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(gdf, x=\"labels_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5816df8-4863-4a33-84a6-37e28e097d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the number of samples by class in our overall dataset (pre-split) are:\")\n",
    "gdf.groupby('labels_cat').count().loc[:, \"field_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c874045-3e9e-4e26-8656-72424fd6577c",
   "metadata": {},
   "source": [
    "#### Recap quiz\n",
    "\n",
    "<details>\n",
    "    <summary><b>How could imbalanced data affect model performance?</b></summary>\n",
    "<ul>\n",
    "<li>The model will not see enough examples of minority classes to learn rules to discriminate them from the input data</li>\n",
    "<li>The model will learn it can achieve good overall accuracy by just predicting majority classes</li>\n",
    "</ul>\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><b>What could we do to fix the class imbalance problem?</b></summary>\n",
    "<ul>\n",
    "<li>Undersample the majority classes</li>\n",
    "<li>Oversample the minority classes</li>\n",
    "<li>Get more data</li>\n",
    "<li>Pool the minority classes to reduce the total number of classes</li>\n",
    "</ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034a1aca-9a4c-4318-80c0-6e09f6d7a2b6",
   "metadata": {},
   "source": [
    "## Data leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbfc1a5-85c2-45c5-93c7-d28d21cfaef8",
   "metadata": {},
   "source": [
    "<a href=\"https://scikit-learn.org/stable/common_pitfalls.html#data-leakage\" target=\"_blank\">Data leakage</a> occurs when information in the test set leaks into the training dataset. This means the test set is not truly independent and does not provide an unbiased assessment of the model's performance on new data. \n",
    "\n",
    "Spatial correlation occurs when observations close to each other are more similar or disimilar than observations further away. This is encapsulated by Tobler's first law of Geography: \"Everything is related to everything else. But near things are more related than distant things.\" \n",
    "\n",
    "Geospatial data is often spatially correlated. This means that data points close to each other are not statistically independent. A random training and test split of spatially correlated data can result in the test dataset not being independent of the training dataset. This is because some of the data in the test set is correlated with data in the training set. Spatial correlation is causing data leakage and the evaluation of model performance using this test set will be biased.\n",
    "\n",
    "#### Recap quiz\n",
    "\n",
    "<details>\n",
    "    <summary><b>How could you generate training and test splits which are not spatially correlated?</b></summary>\n",
    "First, you could explore the spatial correlation in your dataset using techniques such as Moran's I and Local Moran's I statistics. \n",
    "    \n",
    "If you believe that your samples are not likely to be correlated across administrative boundaries such as villages, counties, states etc. you could randomly split your data at the administrative boundary-level as opposed to the sample-level. That is, instead of taking a random hold-out sample of data points for the test set you would take a random sample of administrative units as the test set and all data points inside those units would be your test set. \n",
    "    \n",
    "An alternative strategy if there are no useful administrative boundaries could be to spatially cluster your samples using their coordinates so proximal data points are allocated to the same cluster and randomly hold-out some clusters as the test set. \n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "Let's use the `village` column in our dataset `gdf` as a group to guide generation of training and test sets. We'll ensure that no samples from the same village are in both the training and test sets.\n",
    "\n",
    "<details>\n",
    "    <summary><b>What is our assumption when using villages as the grouping variable?</b></summary>\n",
    "We are assuming that data points in neighbouring villages are not spatially correlated, and, therefore, there is no data leakage from the the test set to the training set. Is this a safe assumption? Do you think villages next to each other will have different agricultural contexts? \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e0f2f-13bb-45c2-8d60-a4817473ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sp = gdf.drop([\"field_id\", \"labels\", \"labels_cat\", \"predicted\", \"index_right\", \"village\", \"geometry\"], axis=1)\n",
    "y_sp = gdf.loc[:, \"labels\"]\n",
    "groups = gdf.loc[:, \"village\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205740f6-7ffe-4a4a-9794-19fdce051084",
   "metadata": {},
   "source": [
    "scikit-learn has a `GroupShuffleSplit` object that has a `split()` method that can be used to generate splits of the dataset. \n",
    "\n",
    "First, we need to create an instance of the `GroupShuffleSplit` object specifying the number of different splits of the dataset that we want to create using the `n_splits` argument. We also use the `train_size` argument to define how much of the data should be allocated to the training and test sets. \n",
    "\n",
    "Here, we only want to create one split of our dataset at the `village` level so we set `n_splits=1`. \n",
    "\n",
    "Then, we call the `split()` method of `gss`, our `GroupShuffleSplit` object, passing in the features (`X_sp`), outcome labels (`y_sp`), and the groups (`groups`). This returns to us a `train_index` and `test_index` specifying the index locations of samples allocated to the training and test set. Passing in `groups` ensures that no samples from the same group (`village`) are in both the training and test sets. \n",
    "\n",
    "We then use the index locations in `train_index` and `test_index` to subset `X_sp` and `y_sp` for model training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e8f56-29e2-46aa-a0d7-c710f13405cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=0)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(gss.split(X_sp, y_sp, groups)):\n",
    "    print(f\"processing split {i}\")\n",
    "    X_train_sp = X_sp.iloc[train_index, :]\n",
    "    X_test_sp = X_sp.iloc[test_index, :]\n",
    "    y_train_sp = y_sp.iloc[train_index]\n",
    "    y_test_sp = y_sp.iloc[test_index]\n",
    "    print(f\"the size of the training features object is {X_train_sp.shape}\") \n",
    "    print(f\"the size of the test features object is {X_test_sp.shape}\")\n",
    "    print(f\"the size of the training outcomes object is {y_train_sp.shape}\")\n",
    "    print(f\"the size of the test outcomes object is {y_test_sp.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92893a3-f84e-4fc6-a28a-3f738a247be7",
   "metadata": {},
   "source": [
    "Now we're ready to train and test our model. \n",
    "\n",
    "Let's train the model and test its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a65082-6369-4719-b428-e213cfef9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and train a random forests model\n",
    "rf_sp = RandomForestClassifier(n_estimators=20, random_state=rng)\n",
    "rf_sp.fit(X_train_sp, y_train_sp.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d751237a-e2a9-4fbf-af03-cac597a3c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sp = rf.predict(X_test_sp)\n",
    "\n",
    "print(classification_report(y_test_sp, y_pred_sp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
