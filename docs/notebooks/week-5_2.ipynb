{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b34d4c31-9726-4b71-9c6f-36dc093de9dd",
   "metadata": {},
   "source": [
    "# Machine Learning 2\n",
    "\n",
    "Machine learning is the process of learning from data to make predictions. **Supervised** machine learning models are trained to predict an outcome based on input data (predictors or features). The model is trained to minimise the error in predictions using a training set where both the outcome labels and input data are known. A key part of the machine learning model development workflow is evaluating model performance. This lab will introduce a technique for evaluating model performance in the context of limited training and test data: cross-validation.\n",
    "\n",
    "Previously, we demonstrated a workflow to develop a machine learning model for a classification task: predicting a field's crop type. In this lab we will develop a machine learning model for a regression task (predicting a continuous number) and evaluate the model using k-fold cross-validation.\n",
    "\n",
    "The task for this lab is to develop and evaluate a machine learning model that can predict smallholder farm maize crop yields in Uganda using remotely sensed vegetation indices as input features.\n",
    "\n",
    "In this lab you'll learn how to use Scikit-learns tools for evaluating models using cross-validation. We'll also introduce approaches for pre-processing categorical data to be used as features in machine learning models and techniques for interpreting the model and exploring how the model is making predictions.\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Run the labs\n",
    "\n",
    "You can run the labs locally on your machine or you can use cloud environments provided by Google Colab. **If you're working with Google Colab be aware that your sessions are temporary and you'll need to take care to save, backup, and download your work.**\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/geog3300-agri3003/coursebook/blob/main/docs/notebooks/week-5_1.ipynb\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "### Download data\n",
    "\n",
    "If you need to download the date for this lab, run the following code snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee11ff-9b90-49ca-898f-8648e4498abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "if \"data_lab-5\" not in os.listdir(os.getcwd()):\n",
    "    subprocess.run('wget \"https://github.com/geog3300-agri3003/lab-data/raw/main/data_lab-5.zip\"', shell=True, capture_output=True, text=True)\n",
    "    subprocess.run('unzip \"data_lab-5.zip\"', shell=True, capture_output=True, text=True)\n",
    "    if \"data_lab-5\" not in os.listdir(os.getcwd()):\n",
    "        print(\"Has a directory called data_lab-5 been downloaded and placed in your working directory? If not, try re-executing this code chunk\")\n",
    "    else:\n",
    "        print(\"Data download OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd204e-7cba-4703-b0ad-2419597d820f",
   "metadata": {},
   "source": [
    "### Working in Colab\n",
    "\n",
    "If you're working in Google Colab, you'll need to install the required packages that don't come with the colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf25fd-f99a-41c0-83fa-14545897a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install rioxarray\n",
    "    !pip install mapclassify\n",
    "    !pip install rasterio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb6fd7e-29e5-4b52-8049-5e44ae1fa890",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "A key part of the machine learning model development workflow is evaluating model performance. This should provide an assessment of how well a model will perform in making predictions on new or unseen data. Machine learning models are data hungry, the more examples the model sees during training the better it will be able to learn mappings that relate input features to outcome labels. However, we also want to test our model on a dataset that is representative of conditions the model might encounter \"in-the-wild\"; this results in setting aside a chunk of our ground truth dataset that cannot be used for model training. Thus, our model is not trained using all available ground truth data.\n",
    "\n",
    "One strategy that is deployed to maximise data available for model training and to provide an assessment of model performance is cross-validation. \n",
    "\n",
    "Before we explore our ground truth dataset for model development, let's quickly introduce cross-validation. Previously, we evaluated the model's performance by removing a random sample of the data prior to model training to use as a test set. \n",
    "\n",
    "#### Recap quiz\n",
    "\n",
    "<details>\n",
    "    <summary><b>Why is it important for the test dataset to be randomly sampled from the ground truth data?</b></summary>\n",
    "We want the test dataset to be representative and unbiased to provide as realistic assessment of the model's performance on new data as possible. \n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><b>What is a potential limitation of using a single hold-out randomly sampled test set for evaluating model performance?</b></summary>\n",
    "With a randomly sampled test set, each time the machine learning model development workflow is repeated new training and test sets would be generated and the model will have different performance scores. Using a single test set means, that by chance, the model could have an overly optimistic or pessimistic assessment of its performance.\n",
    "    \n",
    "Further, by withholding a test set we reduce the amount of data available to train the model. A smaller training dataset can reduce the model's performance. Thus, as we're removing data to form the test set we'd expect the model's error to be larger than if we'd trained the model on the entire dataset. \n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "In k-fold cross-validation there is not a single test set. Instead, the ground truth dataset is randomly split into $k$ folds. For example, if $k=5$ the ground truth dataset would be randomly split into 5 groups. Then, in turn, each fold is held out as a test set and the model is trained using data from the remaining four folds. Each fold takes a turn at being the test set. The model performance can be summarised using the average of the performance metrics generated using each fold. This means the model's performance is less susceptible to being influenced by a chance split of the ground truth data into training and test splits. It also means we can use the whole dataset to train the model and evaluate its performance. \n",
    "\n",
    "### MAPS 2016 Data\n",
    "\n",
    "The dataset we're using is the data from <a href=\"https://web.stanford.edu/~mburke/papers/lobell_et_al_AJAE_2019.pdf\" target=\"_blank\">Lobell et al. (2019)</a>. Their analysis compared different approaches to estimating smallholder maize crop yields in Uganda: farmer reported yields, subplot crop cut samples, full plot crop cut samples, and satellite-based crop yield esimates. \n",
    "\n",
    "Boosting agricultural productivity in smallholder landscapes is important for improving a range of livelihood outcomes including food security and poverty alleviation. Accurate data on smallholder farmer crop production is a key ingredient to guiding development initiatives, government policies / programs, agricultural management and input use, and monitoring progress towards several Sustainable Development Goals. \n",
    "\n",
    "Traditionally, agricultural productivity in smallholder landscapes has been measured using farmer reported crop yields via surveys after harvests. These estimates are subject to considerable error impacting the quality of the data. \n",
    "\n",
    "More accurate measures of crop yield include physically harvesting a sub plot or full plot - crop cutting. However, crop cutting is more costly, time consuming, and requires liaising with farmers to generate large datasets of yield measurements.\n",
    "\n",
    "<a href=\"https://web.stanford.edu/~mburke/papers/lobell_et_al_AJAE_2019.pdf\" target=\"_blank\">Lobell et al. (2019)</a> explore the potential for using satellite data to measure crop yields in smallholder fields to address i) the issue of error in farmer reported yields, and ii) the cost of crop cutting. \n",
    "\n",
    "We're going to use the replication data from their paper and see if we can develop a machine learning model to accurately predict smallholder maize crop yield using satellite data as inputs. As this dataset only has a few hundred data points, we'll use all the data to train the model and test its performance using cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d44f49-a630-4579-9c3f-94cb3ef039c6",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9ab792-a036-482e-bce3-a3bf0bea69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import tree\n",
    "\n",
    "# setup renderer\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"jupyterlab\"\n",
    "\n",
    "rng = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38701b9-b4db-4092-849e-61ef4438b5a4",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96860d38-b20d-40e4-b3bb-80ed9640b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(os.getcwd(), \"data_lab-5\", \"lobell_2019_maize.csv\"))\n",
    "print(f\"the shape of the DataFrame is {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c5252-cca9-4014-9d63-17069176f2ed",
   "metadata": {},
   "source": [
    "### Explore data\n",
    "\n",
    "There data that we have read into `df` includes a range of variables related to crop yield outcomes, farm management and farm type, and satellite-derived vegetation indices from the Sentinel-2 sensor. \n",
    "\n",
    "We'll be using the crop cut maize yield measures from sample sub plots in the fields as our outcome variable here - this is referenced by the column `cc_yield`. The units are Mg/ha.\n",
    "\n",
    "Let's look at the distribution of yield values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed10b72d-57b6-43e1-a588-36ff52c63f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame=df, \n",
    "    x=\"cc_yield\",  \n",
    "    marginal=\"box\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90faef56-15bc-4744-91a4-59826dfa7d37",
   "metadata": {},
   "source": [
    "The `DataFrame` stores Sentinel-2 derived vegetation indices in the following columns:\n",
    "\n",
    "* `gcvi_doy_151` - average field GCVI on day of year 151.\n",
    "* `gcvi_doy_171` - average field GCVI on day of year 171.\n",
    "* `ndvi_doy_151` - average field NDVI on day of year 151.\n",
    "* `ndvi_doy_171` - average field NDVI on day of year 171.\n",
    "* `mtci_doy_151` - average field MTCI on day of year 151.\n",
    "* `mtci_doy_171` - average field MTCI on day of year 171.\n",
    "\n",
    "NDVI is the normalised difference vegetation index. GCVI is the green chlorophyll index. MTCI is the meris terrestrial chlorophyll index. These will be the main features (predictors) in our model.\n",
    "\n",
    "#### Recap quiz\n",
    "\n",
    "**Can you generate scatter plots to explore the correlation between vegetation index values and maize crop yield?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a119b-046e-4baa-9305-01161356ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e73542-8322-4dbb-9f3e-1c20cbd51277",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "    \n",
    "```python\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x = \"gcvi_doy_151\", ## CHANGE THIS FOR DIFFERENT VEGETATION INDICES\n",
    "    y = \"cc_yield\",\n",
    "    trendline = \"ols\",\n",
    "    opacity=0.25,\n",
    "    labels={\"cc_yield\": \"Maize crop yield (Mg/ha)\",\n",
    "           \"gcvi_doy_151\": \"GCVI (DOY 151)\"} ## CHANGE THIS FOR DIFFERENT VEGETATION INDICES\n",
    ")\n",
    "fig.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b2e96-a6b0-4d95-9707-581b3fdfff10",
   "metadata": {},
   "source": [
    "## Cross-validation \n",
    "\n",
    "We'll start by training a linear regression model that predicts maize crop yield as a function of vegetation indices and evaluate its performance using cross validation. \n",
    "\n",
    "Maize crop yield is a continuous variable and we need a metric to evaluate model performance. We'll use the `mean_absolute_error` as the metric which is the mean absolute difference between predicted and observed crop yields. In this case, the mean absolute error will be computed using observations in the held out fold in cross-validation.\n",
    "\n",
    "We'll need to create a linear regression estimator object that we can train (using its `fit()` method). To evaluate the model using cross validation you call the `cross_val_score()` function on the dataset and the estimator. You pass in the metric you wish to use to evaluate the model to the `scoring` argument.\n",
    "\n",
    "We'll also need to use the `dropna()` method of pandas `DataFrame`s to remove missing data before training the model. Scikit-learn models cannot be trained on datasets with `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9080c4-3e5b-4787-8651-c6966f15c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y data\n",
    "\n",
    "# drop nas as Linear Regression object cannot be trained on datasets with missing data\n",
    "df_linear_reg = df.loc[: , [\n",
    "    \"cc_yield\",\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\"]].dropna()\n",
    "\n",
    "# get X\n",
    "X = df_linear_reg.loc[:, [\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\"]]\n",
    "\n",
    "# get Y\n",
    "y = df_linear_reg.loc[:, \"cc_yield\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c24f4-7a2b-4633-97f5-80716bc6430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a LinearRegression estimator object\n",
    "reg = LinearRegression()\n",
    "\n",
    "# evaluate using 5-fold cross validation\n",
    "cv_scores = cross_val_score(reg, X, y, cv=5, scoring=\"neg_mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdbb613-5a3b-4718-9f4e-6f923a9d75f9",
   "metadata": {},
   "source": [
    "`cv_scores` should reference an array of values recording the mean absolute error for the predictions of maize crop yield for each fold. Scikit-learn returns negative mean absolute error values (becauase their convention is that a higher metric values are better than lower metric values which holds for metrics for categorical outcomes such as accuracy). Therefore, we'll want to convert negative mean absolute error values to positive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726461e7-7335-4476-bae5-9c26a5635239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print cross validation test scores\n",
    "for i, mae in enumerate(cv_scores):\n",
    "    print(f\"the mae for the {i}th fold is {round(abs(mae), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ea319-7fff-4fbb-a73b-f31fa88c754f",
   "metadata": {},
   "source": [
    "If we want to use more than one metric to evaluate the model, we can pass in a list of metrics to the `scoring` argument. Let's also estimate the mean squared error value as well as the mean absolute error. The mean squared error penalises the model more for predictions with larger error.\n",
    "\n",
    "To use multiple metrics we need to use the `cross_validate()` function instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8bcd27-4ff2-437a-8a24-a0925434bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate using 5-fold cross validation\n",
    "cv_scores = cross_validate(reg, X, y, cv=5, scoring=[\"neg_mean_absolute_error\", \"neg_mean_squared_error\"])\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f2a63-f319-44fa-a9a4-6abde036954f",
   "metadata": {},
   "source": [
    "#### Recap quiz\n",
    "\n",
    "**Can you estimate the mean mean absolute error and mean mean squared error across the five test folds using the `cv_scores` dictionary object?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc82dda-8b21-44e2-9c9e-ef8a4dcc068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066bbfb4-a1a2-45a0-b8e4-4ce503243cf9",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "\n",
    "```python\n",
    "print(f\"mean mae: {abs(cv_scores['test_neg_mean_absolute_error'].mean())}\")\n",
    "print(f\"mean mse: {cv_scores['test_neg_mean_squared_error'].mean()}\")\n",
    "```\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "**Can you train and evaluate a random forests model using 5-fold cross-validation to see if it improves the predictive performance?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244ef1c-3b14-4bce-a97e-f03341b0e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5dc001-c5d7-4f16-8bd8-1043887d6a36",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "    \n",
    "```python\n",
    "rf = RandomForestRegressor(n_estimators=20, random_state=rng)\n",
    "rf_cv_scores = cross_validate(rf, X, y, cv=5, scoring=[\"neg_mean_absolute_error\"])\n",
    "rf_cv_scores\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faae14fd-d33e-45d8-a33f-c9a7cbef8081",
   "metadata": {},
   "source": [
    "## Categorical features\n",
    "\n",
    "In our `DataFrame` there are some categorical variables that could help improve our predictions of crop yield. These include the slope, soil type, and soil quality variables. These variables are `str` type. We can only pass numeric data into our models; therefore, we'll need to recode the text data to a numeric representation. \n",
    "\n",
    "One approach for recoding categorical data is one hot encoding. Each unique value in a one hot encoded categorical variable is assigned a new column in the `DataFrame`. For rows when this value is present a value of one is assigned and zero otherwise. \n",
    "\n",
    "Let's one hot encode the slope variable `slope_sr` to illustrate this concept. \n",
    "\n",
    "The pandas `get_dummies()` function can be used to one hot encode a column in a `DataFrame`. The `get_dummies()` function has a `columns` argument that takes a list of column names that will be one hot encoded.\n",
    "\n",
    "First, let's visualise our `DataFrame` `df` and inspect the values in the `slope_sr` column. You should see the values \"FLAT\", \"MODERATE SLOPE\", \"SLIGHT SLOPE\", \"STEEP SLOPE\" as `str` data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58616a32-64da-42fa-8537-11e19eebecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f97a4f-10af-4645-aa3a-65e523bb8ebe",
   "metadata": {},
   "source": [
    "Now, let's one hot encode the `slope_sr` variable and see how it is represented as numeric data. (scroll to the far right of the displayed `DataFrame`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed03e6-3709-4037-9a72-a77bf35f72fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = pd.get_dummies(df, columns=[\"slope_sr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189816d7-0170-464e-b446-9de3ef077844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e4d33-d631-48c7-b521-079dbf67babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b5f20-f2b2-4f18-86fb-aaf2a56e8e87",
   "metadata": {},
   "source": [
    "Now, let's retrain our linear regression model using slope as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc6a23-40c7-4533-91a7-a05f0a458e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y data\n",
    "\n",
    "## NOTE WE ARE USING df_cat here!!\n",
    "# drop nas as Linear Regression object cannot be trained on datasets with missing data\n",
    "df_linear_reg = df_cat.loc[: , [\n",
    "    \"cc_yield\",\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\",\n",
    "    \"slope_sr_FLAT\",\n",
    "    \"slope_sr_MODERATE SLOPE\",\n",
    "    \"slope_sr_SLIGHT SLOPE\",\n",
    "    \"slope_sr_STEEP SLOPE\"]].dropna()\n",
    "\n",
    "# get X\n",
    "X = df_linear_reg.loc[:, [\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\",\n",
    "    \"slope_sr_FLAT\",\n",
    "    \"slope_sr_MODERATE SLOPE\",\n",
    "    \"slope_sr_SLIGHT SLOPE\",\n",
    "    \"slope_sr_STEEP SLOPE\"]]\n",
    "\n",
    "# get Y\n",
    "y = df_linear_reg.loc[:, \"cc_yield\"]\n",
    "\n",
    "# create a LinearRegression estimator object\n",
    "reg = LinearRegression()\n",
    "\n",
    "# evaluate using 5-fold cross validation\n",
    "cv_scores = cross_validate(reg, X, y, cv=5, scoring=[\"neg_mean_absolute_error\", \"neg_mean_squared_error\"])\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4330b0-1dce-4836-af40-109ea4af4fe8",
   "metadata": {},
   "source": [
    "#### Recap quiz\n",
    "\n",
    "**Can you also recode the soil type `soiltype_sr` and `soilqual_sr` variables from categorical to numeric using one hot encoding? Reference the result with the variable `df_2`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e1123-05e7-4268-8588-c440ac5be5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fd3eb-9b30-4a1d-8c8b-80de802c448f",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "\n",
    "```python\n",
    "df_2 = pd.get_dummies(df, columns=[\"slope_sr\", \"soiltype_sr\", \"soilqual_sr\"])\n",
    "df_2.head()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b0a2b0-2851-4a19-bb21-25a0671e53f0",
   "metadata": {},
   "source": [
    "**Can you use `df_2` with `soiltype_sr`, `slope_sr`, and `soilqual_sr` as training data in a random forests model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca1587-f020-42af-8f4a-85babcaf7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADD CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7b7f82-5bdf-4fdd-96f0-961f652f5b9d",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer</b></summary>\n",
    "\n",
    "```python\n",
    "# get X and y data\n",
    "\n",
    "# NOTE WE USE df_2 here!!\n",
    "# drop nas as Linear Regression object cannot be trained on datasets with missing data\n",
    "df_linear_reg = df_2.loc[: , [\n",
    "    \"cc_yield\",\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\",\n",
    "    \"slope_sr_FLAT\",\n",
    "    \"slope_sr_MODERATE SLOPE\", \n",
    "    \"slope_sr_SLIGHT SLOPE\",\n",
    "    \"slope_sr_STEEP SLOPE\", \n",
    "    \"soiltype_sr_CLAY\", \n",
    "    \"soiltype_sr_LOAM\",\n",
    "    \"soiltype_sr_OTHER (SPECIFY)\", \n",
    "    \"soiltype_sr_SANDY\", \n",
    "    \"soilqual_sr_FAIR\",\n",
    "    \"soilqual_sr_GOOD\", \n",
    "    \"soilqual_sr_POOR\"]].dropna()\n",
    "\n",
    "# get X\n",
    "X = df_linear_reg.loc[:, [\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\",\n",
    "    \"slope_sr_FLAT\",\n",
    "    \"slope_sr_MODERATE SLOPE\", \n",
    "    \"slope_sr_SLIGHT SLOPE\",\n",
    "    \"slope_sr_STEEP SLOPE\", \n",
    "    \"soiltype_sr_CLAY\", \n",
    "    \"soiltype_sr_LOAM\",\n",
    "    \"soiltype_sr_OTHER (SPECIFY)\", \n",
    "    \"soiltype_sr_SANDY\", \n",
    "    \"soilqual_sr_FAIR\",\n",
    "    \"soilqual_sr_GOOD\", \n",
    "    \"soilqual_sr_POOR\"]]\n",
    "\n",
    "# get Y\n",
    "y = df_linear_reg.loc[:, \"cc_yield\"]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=20, random_state=rng)\n",
    "rf_cv_scores = cross_validate(rf, X, y, cv=5, scoring=[\"neg_mean_absolute_error\"])\n",
    "rf_cv_scores\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a737f-4cc9-4053-8ac2-3022288c6a06",
   "metadata": {},
   "source": [
    "## Controlling randomness\n",
    "\n",
    "Some elements of the machine learning workflow are inherently random. For example, allocating data points to folds in k-fold cross-validation and bootstrap sampling of data to train decision trees in random forests. \n",
    "\n",
    "While this randomness is important (e.g. to ensure unbiased estimates of model performance when using cross-validation) it presents a challenge for reproducible results. The randomness of estimators (e.g. an instance of `RandomForestsRegressor()` or a cross-validation splitter is controlled by a `random_state` parameter. \n",
    "\n",
    "Some general tips on setting the `random_state` parameter:\n",
    "\n",
    "* Never set `random_state` to `None` for reproducible results.\n",
    "* Create a `RandomState` variable at the start of your program and pass it to all functions that accept a `random_state` argument. Look at the start of this notebook and see if you can sport where we create a `RandomState` variable just after we import the modules.\n",
    "* If you're generating cross validation splits, use an integer value instead of a `RandomState` instance.\n",
    "\n",
    "This is quite an advanced topic, but important to ensure your results are reproducible. Generally, following the guidelines above is the best way to go. However, you can read more about this topic <a href=\"https://scikit-learn.org/stable/common_pitfalls.html#general-recommendations\" target=\"_blank\">here</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b961ea-d66a-4704-bdae-c894f57a4df4",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "Machine learning models are often considered \"black boxes\". That is, it is not clear how the model is using input features to make predictions and what relationships it has learnt to relate features to outcomes.\n",
    "\n",
    "One strategy to make machine learning models more interpretable is to compute feature importance (or permutation importance). The feature importance is a measure of how much the error in a model's prediction increases when a feature is omitted from the model. Features with larger importance scores are therefore more important for making accurate predictions. \n",
    "\n",
    "The permutation feature importance score is computed as the decrease in a model's performance when a feature is randomly shuffled (permuted). This should ensure there is no relationship between the feature and the outcome. \n",
    "\n",
    "You can read more about feature importance in the <a href=\"\" target=\"_blank\">Interpretable Machine Learning</a> book and in the Scikit-learn <a href=\"https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance\" target=\"_blank\">docs</a>.\n",
    "\n",
    "First, let's set up and fit a linear regression model that predicts maize crop yield using vegetation indices and field characteristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a15b07-18f1-484f-b971-551f543b7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE we use df_cat here!!\n",
    "\n",
    "# drop nas as Linear Regression object cannot be trained on datasets with missing data\n",
    "df_linear_reg = df_cat.loc[: , [\n",
    "    \"cc_yield\",\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\",\n",
    "    \"slope_sr_FLAT\",\n",
    "    \"slope_sr_MODERATE SLOPE\", \n",
    "    \"slope_sr_SLIGHT SLOPE\",\n",
    "    \"slope_sr_STEEP SLOPE\"]].dropna()\n",
    "\n",
    "# get X\n",
    "X = df_linear_reg.loc[:, [\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\",\n",
    "    \"slope_sr_FLAT\",\n",
    "    \"slope_sr_MODERATE SLOPE\", \n",
    "    \"slope_sr_SLIGHT SLOPE\",\n",
    "    \"slope_sr_STEEP SLOPE\"]]\n",
    "\n",
    "# get Y\n",
    "y = df_linear_reg.loc[:, \"cc_yield\"]\n",
    "\n",
    "# create a LinearRegression estimator object\n",
    "reg = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05409f56-bcb8-4b00-be3c-c704ac1302a6",
   "metadata": {},
   "source": [
    "Now we compute permuation importance using 30 shuffles of each feature. The results referenced by `p_imp` is a dictionary object with arrays showing the model error when each feature was randomly shuffled and for each repeat of the random shuffling. It also has a property `importances_mean` which is the mean increase in error across all iterations when a feature was randomly shuffled. \n",
    "\n",
    "We use the `permutation_importance()` function and pass in the `LinearRegression()` estimator, the features and labels data (`X` and `y`), the metric to evaluate model performance to the `scoring` argument, and specify the number of repeats with the `n_repeats` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96958f2-b92b-4e49-9a2c-fe8db276e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_imp = permutation_importance(reg, X, y, scoring=\"neg_mean_absolute_error\", n_repeats=30, random_state=rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776e2279-9eb4-4442-bc7a-f446d39a311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_imp[\"importances_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81005d5b-5224-43be-a64f-de8c8cbd4e8e",
   "metadata": {},
   "source": [
    "Let's use this data to make a permutation importance plot that visualises the increase in error when a feature is randomly shuffled.\n",
    "\n",
    "First, let's get a list of column headings for each feature and convert the negative mean absolute error values to positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461ea84-a365-4c77-a449-e1bcdd4dc286",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X.columns\n",
    "p_imp = abs(p_imp[\"importances_mean\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2459a1f-85af-422f-ad3c-8c5580c3c546",
   "metadata": {},
   "source": [
    "Now, let's combine the feature labels and importance values into a `DataFrame`, sort the `DataFrame` by the importance scores, and generate a bar plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b959d-3643-4da8-a809-9cacd9595695",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_imp_df = pd.DataFrame({\"feature\": columns, \"importance\": p_imp})\n",
    "p_imp_df = p_imp_df.sort_values(by=[\"importance\"], ascending=True)\n",
    "p_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe840a2-6219-44d1-b1e2-b987f41f50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(p_imp_df, y=\"feature\", x=\"importance\", height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c63f9-a46a-46cc-823f-bf0dd4cf832c",
   "metadata": {},
   "source": [
    "#### Recap quiz\n",
    "\n",
    "<details>\n",
    "    <summary><b>Do the feature importance results make sense? Can you explain them?</b></summary>\n",
    "The most important features for predictive importance are the vegetation indices. There is an established literature that vegetation indices are correlated with, and predictive of, crop yields. \n",
    "    \n",
    "However, we should be cautious in interpreting the differences between vegetation indices as it is likely that the vegetation indices are correlated (even if they're designed to capture different information about vegetation growth and condition). When one of the vegetation indices is permuted (shuffled), it is likely the model will still have access to information about this feature through other features in the model which it is correlated with. You can read more about this <a href=\"https://scikit-learn.org/stable/modules/permutation_importance.html#misleading-values-on-strongly-correlated-features\" target=\"_blank\">here</a>.\n",
    "</details>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<details>\n",
    "    <summary><b>Here, we computed the feature importance scores using the training data. Can you think of a limit to computing feature importance with the training set compared to using the test set?</b></summary>\n",
    "Computing feature importance using a held-out test set would indicate which features are important for the model's capacity to generalise well to unseen data. Features that are important for the training set migh be causing the model to overfit. You can read more about this <a href=\"https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-feature-importance\" target=\"_blank\">here</a>.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901443c8-b607-49d2-9d5d-b27a6fb7d9e4",
   "metadata": {},
   "source": [
    "## Final activity\n",
    "\n",
    "You will notice in `df` that there are some columns related to mixed cropping in some of the maize fields (e.g.`intercrop_legume`, `intercrop_cassava`, `crop_rotation`, `purestand`). One issue that could be affecting model performance is that we're using average vegetation indices across the whole field but not all of the field is maize cropping. This means that our vegetation index data is not purely capturing a maize crop signal but also the condition of other crops. We might be able to improve the model's performance if we restrict our analysis to pure maize fields or control for the effect of mixed cropping. \n",
    "\n",
    "**Can you create a training set that will use one or more of the `intercrop_legume`, `intercrop_cassava`, `crop_rotation`, and `purestand` variables to train a model to predict maize yield that accounts for the mixed cropping practices inherent in smallholder systems in Uganda. Evaluate your model using cross-validation and justify the rationale for your approach.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af28d32-d91e-493b-ba58-362f0c1336c5",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer 1</b></summary>\n",
    "\n",
    "Here, we filter out any data points representing mixed cropping fields using the condition `df[purestand] == 1` where a value of 1 in the `purestand` column indicates pure maize cropping. \n",
    "    \n",
    "This approach means our vegetation indices should just be capturing information about maize crop condition. \n",
    "    \n",
    "```python\n",
    "# get X and y data\n",
    "\n",
    "# drop mixed cropping fields\n",
    "df_pure = df.loc[df[\"purestand\"] == 1, :]\n",
    "\n",
    "# one hot encode categorical predictors\n",
    "df_pure = pd.get_dummies(df_pure, columns=[\"slope_sr\", \"soiltype_sr\", \"soilqual_sr\"])\n",
    "\n",
    "# drop nas as Linear Regression object cannot be trained on datasets with missing data\n",
    "df_linear_reg = df_pure.loc[: , [\n",
    "    \"cc_yield\",\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\",\n",
    "    \"slope_sr_FLAT\",\n",
    "    \"slope_sr_MODERATE SLOPE\",\n",
    "    \"slope_sr_SLIGHT SLOPE\",\n",
    "    \"slope_sr_STEEP SLOPE\"]].dropna()\n",
    "\n",
    "# get X\n",
    "X = df_linear_reg.loc[:, [\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\",\n",
    "    \"slope_sr_FLAT\",\n",
    "    \"slope_sr_MODERATE SLOPE\",\n",
    "    \"slope_sr_SLIGHT SLOPE\",\n",
    "    \"slope_sr_STEEP SLOPE\"]]\n",
    "\n",
    "# get Y\n",
    "y = df_linear_reg.loc[:, \"cc_yield\"]\n",
    "\n",
    "# create a LinearRegression estimator object\n",
    "reg = LinearRegression()\n",
    "\n",
    "# evaluate using 5-fold cross validation\n",
    "cv_scores = cross_validate(reg, X, y, cv=5, scoring=[\"neg_mean_absolute_error\"])\n",
    "cv_scores\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdef40-d770-4363-8382-3c837d88d691",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>answer 2</b></summary>\n",
    "\n",
    "Here, we control for the presence of mixed cropping by using intercropping and crop rotation variables as features in the model.  \n",
    "    \n",
    "This approach might be suited to generating a maize crop prediction model that's applicable to the Ugandan context where mixed cropping is prevalent and pure maize fields are uncommon.  \n",
    "    \n",
    "```python\n",
    "# get X and y data\n",
    "\n",
    "# one hot encode categorical predictors\n",
    "df_2 = pd.get_dummies(df, columns=[\"slope_sr\", \"soiltype_sr\", \"soilqual_sr\"])\n",
    "\n",
    "# drop nas as Linear Regression object cannot be trained on datasets with missing data\n",
    "df_linear_reg = df_2.loc[: , [\n",
    "    \"cc_yield\",\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\",\n",
    "    \"slope_sr_FLAT\",\n",
    "    \"slope_sr_MODERATE SLOPE\",\n",
    "    \"slope_sr_SLIGHT SLOPE\",\n",
    "    \"slope_sr_STEEP SLOPE\",\n",
    "    \"intercrop_legume\",\n",
    "    \"intercrop_cassava\",\n",
    "    \"crop_rotation\"]].dropna()\n",
    "\n",
    "# get X\n",
    "X = df_linear_reg.loc[:, [\n",
    "    \"gcvi_doy_151\", \n",
    "    \"gcvi_doy_171\", \n",
    "    \"ndvi_doy_151\", \n",
    "    \"ndvi_doy_171\", \n",
    "    \"mtci_doy_151\", \n",
    "    \"mtci_doy_171\",\n",
    "    \"slope_sr_FLAT\",\n",
    "    \"slope_sr_MODERATE SLOPE\",\n",
    "    \"slope_sr_SLIGHT SLOPE\",\n",
    "    \"slope_sr_STEEP SLOPE\",\n",
    "    \"intercrop_legume\",\n",
    "    \"intercrop_cassava\",\n",
    "    \"crop_rotation\"]]\n",
    "\n",
    "# get Y\n",
    "y = df_linear_reg.loc[:, \"cc_yield\"]\n",
    "\n",
    "# create a LinearRegression estimator object\n",
    "reg = LinearRegression()\n",
    "\n",
    "# evaluate using 5-fold cross validation\n",
    "cv_scores = cross_validate(reg, X, y, cv=5, scoring=[\"neg_mean_absolute_error\"])\n",
    "cv_scores\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
