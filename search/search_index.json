{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GEOG3300 and AGRI3003 - Semester 1 2024","text":""},{"location":"#welcome","title":"Welcome","text":"<p>This is the online course book for Advanced Spatial Analysis (3300) and Decisions from Data in Agriculture (3003).</p> <p>There are rapid changes in data science and technology/sensors that are driving change across the environmental and agricultural sectors. This unit focuses on student learning through practical and applied laboratories, using Python, and collecting field data using uncrewed aerial vehicles (UAVs). Students will develop skills to manipulate, transform, analyse, and visualise big spatial and non-spatial data to provide solutions to the big landscape and agricultural questions.</p> <p>This course will teach students foundational skills and knowledge required to implement spatial and non-spatial data analysis workflows programmatically, to handle and analyse \u201cbig\u201d data, and to operate in cloud-based environments.</p> <p>There are three overarching themes are:</p> <ul> <li> <p>Programming: analysis doesn\u2019t scale without code, programming skills are required to use many software packages and tools for spatial data analysis.</p> </li> <li> <p>Big data: various sensors are generating databases that are growing in size and variety. Increasingly specialist software and data formats are required to handle big data.</p> </li> <li> <p>Cloud-based environments: it\u2019s easier to move the question to the data than to make big data mobile. Data and computer processing are often located on remote computers - we need to know how to get there. </p> </li> </ul>"},{"location":"#computer-labs","title":"Computer labs","text":"<p>The material and concepts will be delivered in computer workshops. In the first session, the instructor will introduce the week's content and explain key concepts. Then for the reminder of the first session and the second session students will work through practical examples and practice exercises in a Jupyter notebook environment with support from instructors. </p>"},{"location":"notebooks/week-1_2/","title":"Week 1 2","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport subprocess\n\nif \"data_lab-1_2\" not in os.listdir(os.getcwd()):\n    subprocess.run('wget \"https://github.com/geog3300-agri3003/lab-data/raw/main/data_lab-1_2.zip\"', shell=True, capture_output=True, text=True)\n    subprocess.run('unzip \"data_lab-1_2.zip\"', shell=True, capture_output=True, text=True)\n    if \"data_lab-2_1\" not in os.listdir(os.getcwd()):\n        print(\"Has a directory called data_lab-1_2 been downloaded and placed in your working directory? If not, try re-executing this code chunk\")\n    else:\n        print(\"Data download OK\")\n</pre> import os import subprocess  if \"data_lab-1_2\" not in os.listdir(os.getcwd()):     subprocess.run('wget \"https://github.com/geog3300-agri3003/lab-data/raw/main/data_lab-1_2.zip\"', shell=True, capture_output=True, text=True)     subprocess.run('unzip \"data_lab-1_2.zip\"', shell=True, capture_output=True, text=True)     if \"data_lab-2_1\" not in os.listdir(os.getcwd()):         print(\"Has a directory called data_lab-1_2 been downloaded and placed in your working directory? If not, try re-executing this code chunk\")     else:         print(\"Data download OK\") In\u00a0[\u00a0]: Copied! <pre>if 'google.colab' in str(get_ipython()):\n    !pip install mapclassify\n    !pip install rasterio\n</pre> if 'google.colab' in str(get_ipython()):     !pip install mapclassify     !pip install rasterio In\u00a0[\u00a0]: Copied! <pre># Import modules\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nimport plotly.io as pio\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\"\n</pre> # Import modules import os import pandas as pd import geopandas as gpd import plotly.express as px import plotly.io as pio  # setup renderer if 'google.colab' in str(get_ipython()):     pio.renderers.default = \"colab\" else:     pio.renderers.default = \"jupyterlab\" In\u00a0[\u00a0]: Copied! <pre># Load the canola yield data from the harvester\nharvester_data_path = os.path.join(os.getcwd(), \"data_lab-1_2\")\n\n# Get a list of canola yield data\nharvester_data_files = os.listdir(harvester_data_path)\n\n# Combine the csv files into one data frame\ndfs = []\n\nfor i in harvester_data_files:\n    if i.endswith(\".csv\"):\n        tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))\n        dfs.append(tmp_df)\n\ndf = pd.concat(dfs, axis=0)\n\n# Inspect the data frame\ndf.head()\n</pre> # Load the canola yield data from the harvester harvester_data_path = os.path.join(os.getcwd(), \"data_lab-1_2\")  # Get a list of canola yield data harvester_data_files = os.listdir(harvester_data_path)  # Combine the csv files into one data frame dfs = []  for i in harvester_data_files:     if i.endswith(\".csv\"):         tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))         dfs.append(tmp_df)  df = pd.concat(dfs, axis=0)  # Inspect the data frame df.head() In\u00a0[\u00a0]: Copied! <pre># Transform the yield data to a spatial format\npoints = gpd.points_from_xy(df[\"Longitude\"], df[\"Latitude\"], crs=\"EPSG:4326\")\ngdf = gpd.GeoDataFrame(df, geometry=points)\n\n# Visualise the crop yield data on a web map\nbasemap = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\nattribution = \"Tiles &amp;copy; Esri &amp;mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community\"\ngdf.explore(column=\"DryYield\", cmap=\"plasma\", tooltip=\"DryYield\", vmax=2, tiles=basemap, attr=attribution)\n</pre> # Transform the yield data to a spatial format points = gpd.points_from_xy(df[\"Longitude\"], df[\"Latitude\"], crs=\"EPSG:4326\") gdf = gpd.GeoDataFrame(df, geometry=points)  # Visualise the crop yield data on a web map basemap = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\" attribution = \"Tiles \u00a9 Esri \u2014 Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community\" gdf.explore(column=\"DryYield\", cmap=\"plasma\", tooltip=\"DryYield\", vmax=2, tiles=basemap, attr=attribution) In\u00a0[\u00a0]: Copied! <pre>print(type(0.227))\n</pre> print(type(0.227)) In\u00a0[\u00a0]: Copied! <pre>print(type(\"a string\"))\nprint(\"a string\")\n</pre> print(type(\"a string\")) print(\"a string\") <p>Let's check how the sample id names in the canola yield dataset are represented. First, let's remind ourselves what the <code>DataFrame</code> of the yield dataset looks like.</p> In\u00a0[\u00a0]: Copied! <pre>df.head()\n</pre> df.head() In\u00a0[\u00a0]: Copied! <pre># get the first field name value\nfield_name = df.loc[:, \"sample_id\"].to_list()[0]\nprint(type(field_name))\nprint(field_name)\n</pre> # get the first field name value field_name = df.loc[:, \"sample_id\"].to_list()[0] print(type(field_name)) print(field_name) In\u00a0[\u00a0]: Copied! <pre>print(type(0.277 &gt; 0.2))\nprint(0.227 &gt; 0.2)\n</pre> print(type(0.277 &gt; 0.2)) print(0.227 &gt; 0.2) <p>We can use the <code>isinstance(value, type)</code> function to test if a data value matches a data type. Let's test if our crop yield value is numeric or string.</p> In\u00a0[\u00a0]: Copied! <pre>print(isinstance(0.227, float))\nprint(isinstance(0.227, str))\n</pre> print(isinstance(0.227, float)) print(isinstance(0.227, str)) In\u00a0[\u00a0]: Copied! <pre>[\"bf66_sample_1\", \"bf66_sample_2\"]\n</pre> [\"bf66_sample_1\", \"bf66_sample_2\"] <p>Lists allow us to store duplicate values. The following is a valid list.</p> In\u00a0[\u00a0]: Copied! <pre>[\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_2\"]\n</pre> [\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_2\"] <p>A key feature of lists are that they can be modified in place. This makes lists useful data structures for tasks when the number of objects that we want to store in a collection can change during our program's execution. We can use functions such as <code>.append()</code> to add objects to the end of a list.</p> In\u00a0[\u00a0]: Copied! <pre>sample_id_list = [\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_2\"]\nsample_id_list.append(\"bf66_sample_3\")\nprint(sample_id_list)\n</pre> sample_id_list = [\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_2\"] sample_id_list.append(\"bf66_sample_3\") print(sample_id_list) Using lists in our Python program to read in CSV files on harvester crop yield data <p>In our Python program above, we took advantage of the fact that lists can be modified in place to loop over the CSV files in a directory, import them in as pandas <code>DataFrames</code>, and append the <code>DataFrames</code> to the list.</p> <pre># Combine the csv files into one data frame\ndfs = []\n\nfor i in harvester_data_files:\n    if i.endswith(\".csv\"):\n        tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))\n        dfs.append(tmp_df)\n</pre> <p>Here, we start with an empty list <code>dfs</code> denoted by just square brackets <code>[]</code>. Then, successively, a new object is added to <code>dfs</code> using the <code>append()</code> function. We finish with a list storing three pandas <code>DataFrames</code>. This demonstrates how we change the length and contents of a list during the execution of a program. We have gone from a list with zero elements to a list a list with three elements.</p> <p></p> <p>We can store any Python object in a list. We can also mix the types of objects stored in lists. The following is a valid list.</p> In\u00a0[\u00a0]: Copied! <pre>[1, 2, \"not a number\", None]\n</pre> [1, 2, \"not a number\", None] <p>Lists are ordered collections of data. If you add an element to a list it will be appended to the last position. List items can be accessed by their index location with the first element having index <code>0</code>.</p> In\u00a0[\u00a0]: Copied! <pre>print(sample_id_list)\nprint(\"The first element in sample_id_list is at index 0: \", sample_id_list[0])\nprint(\"The second element in sample_id_list is at index 1: \", sample_id_list[1])\nprint(\"The third element in sample_id_list is at index 2: \", sample_id_list[2])\n</pre> print(sample_id_list) print(\"The first element in sample_id_list is at index 0: \", sample_id_list[0]) print(\"The second element in sample_id_list is at index 1: \", sample_id_list[1]) print(\"The third element in sample_id_list is at index 2: \", sample_id_list[2]) <p>We can use index locations of elements in a list to create slices of list elements. For example, <code>sample_id_list[0:2]</code> would slice out the first two elements of the list. Note, the element referenced by the index in the final number of the slice is excluded.</p> In\u00a0[\u00a0]: Copied! <pre>print(sample_id_list[0:2])\n</pre> print(sample_id_list[0:2]) In\u00a0[\u00a0]: Copied! <pre>(116.804075, -33.889203)\n</pre> (116.804075, -33.889203) <p>Here, we have created a tuple with two numeric objects. Similar to lists we can access tuple elements by their index locations. Note the use of the <code>[]</code> operator to access elements by their index location.</p> In\u00a0[\u00a0]: Copied! <pre>print(\"First tuple element: \", (116.804075, -33.889203)[0])\n</pre> print(\"First tuple element: \", (116.804075, -33.889203)[0]) In\u00a0[\u00a0]: Copied! <pre>print(\"Second tuple element: \", (116.804075, -33.889203)[1])\n</pre> print(\"Second tuple element: \", (116.804075, -33.889203)[1]) <p>As tuples are fixed-length and unchangeable, we cannot append elements to them in the same way we could with lists. This makes them useful data structures for storing data values which we don't want to change. For example, coorindate pairs that describe a location's x and y values (e.g. longitude and latitude) have two elements. Therefore, a tuple could be a suitable data format to store coordinate pairs.</p> <p>The shape of pandas <code>DataFrames</code> is also a tuple. A <code>DataFrame</code> has two dimensions: number of rows and number of columns. Thus, a tuple is a sensible data structure for storing the shape of <code>DataFrame</code> objects.</p> In\u00a0[\u00a0]: Copied! <pre>df.shape\n</pre> df.shape <p>To demonstrate that we cannot change tuple values, let's try and update the number of rows in the tuple storing the shape of <code>df</code>.</p> In\u00a0[\u00a0]: Copied! <pre>df.shape[0] = 5\n</pre> df.shape[0] = 5 <p>We have returned a <code>TypeError</code> informing us the tuple objects do not support item assigment (adding new items to the tuple).</p> <p>Similar to lists, elements of a tuple are ordered and can be duplicated.</p> In\u00a0[\u00a0]: Copied! <pre>{\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_2\", \"bf66_sample_3\"}\n</pre> {\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_2\", \"bf66_sample_3\"} In\u00a0[\u00a0]: Copied! <pre>{1, 2, 3, 3, 4}\n</pre> {1, 2, 3, 3, 4} <p>As sets are not ordered, we cannot access their elements by numeric index locations.</p> In\u00a0[\u00a0]: Copied! <pre># This fails as set objects are not subscriptable\n{\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"}[0]\n</pre> # This fails as set objects are not subscriptable {\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"}[0] <p>We can access set elements by looping over them or checking if a value is in the set.</p> In\u00a0[\u00a0]: Copied! <pre>for i in {\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"}:\n    print(i)\n</pre> for i in {\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"}:     print(i) In\u00a0[\u00a0]: Copied! <pre>print(\"Checking if 'bf66_sample_1' is in the set:\")\nprint(\"bf66_sample_1\" in {\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"})\n</pre> print(\"Checking if 'bf66_sample_1' is in the set:\") print(\"bf66_sample_1\" in {\"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"}) <p>Similar to tuples, sets are unchangeable (immutable). Once created, we cannot change the set's values in our programs.</p> In\u00a0[\u00a0]: Copied! <pre>{\n\"Elevation(m)\": [213, 222, 214, 254],\n\"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"],\n\"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"]\n}\n</pre> { \"Elevation(m)\": [213, 222, 214, 254], \"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"], \"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"] } <p>Keys of dictionary objects cannot be duplicated. For example:</p> In\u00a0[\u00a0]: Copied! <pre>{\n\"Elevation(m)\": [213, 222, 214, 254],\n\"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"],\n\"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"],\n\"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"]\n}\n</pre> { \"Elevation(m)\": [213, 222, 214, 254], \"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"], \"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"], \"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"] } <p>To access elements of a dictionary object we can refer to its key. The following code snippet extracts a list of dates from the dictionary object.</p> In\u00a0[\u00a0]: Copied! <pre>demo_dict = {\"Elevation(m)\": [213, 222, 214, 254],\n    \"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"],\n    \"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"]}\ndates = demo_dict[\"Date\"]\ndates\n</pre> demo_dict = {\"Elevation(m)\": [213, 222, 214, 254],     \"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"],     \"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"]} dates = demo_dict[\"Date\"] dates <p>Dictionary objects have a <code>get()</code> function that we can use to extract elements.</p> In\u00a0[\u00a0]: Copied! <pre>dates = demo_dict.get(\"Date\")\ndates\n</pre> dates = demo_dict.get(\"Date\") dates <p>Dictionary objects also have a <code>keys()</code> function that returns a list of keys.</p> In\u00a0[\u00a0]: Copied! <pre>demo_dict.keys()\n</pre> demo_dict.keys() <p>There is also a <code>values()</code> function that we can use to return a list of values.</p> In\u00a0[\u00a0]: Copied! <pre>demo_dict.values()\n</pre> demo_dict.values() <p>And, the <code>items()</code> function returns a tuple of key-value pairs.</p> In\u00a0[\u00a0]: Copied! <pre>demo_dict.items()\n</pre> demo_dict.items() <p>We can add elements to a dictionary object by providing a new key with corresponding values.</p> In\u00a0[\u00a0]: Copied! <pre>demo_dict[\"yield\"] = [1.45, 2.5, 3, 2.8, 5.5]\ndemo_dict\n</pre> demo_dict[\"yield\"] = [1.45, 2.5, 3, 2.8, 5.5] demo_dict <p>You will notice that the list of yield values we just added to the dictionary has a different number of elements to the other elements in the values slots.</p> <p>Edit the following code snippet to retrieve and print the 3rd element in <code>x</code>.</p> In\u00a0[\u00a0]: Copied! <pre>x = [1, 2, 3, 4]\n# add code here #\n</pre> x = [1, 2, 3, 4] # add code here # answer <pre>print(x[2])\n</pre> <p>Edit the following code snippet to retrieve and print the first element in <code>z</code>.</p> In\u00a0[\u00a0]: Copied! <pre>z = (4, 5)\n# add code here #\n</pre> z = (4, 5) # add code here # answer <pre>print(z[0])\n</pre> <p>What is the data type of the value associated with the <code>field</code> key in the dict <code>z</code>? Retrieve this value from the dict and print its type.</p> In\u00a0[\u00a0]: Copied! <pre>z = {\n\"name\": \"farm 1\",\n\"field\": 439,\n\"crop\": \"canola\"\n}\n# add code here #\n</pre> z = { \"name\": \"farm 1\", \"field\": 439, \"crop\": \"canola\" } # add code here # answer <pre>print(type(z[\"field\"]))\n</pre> In\u00a0[\u00a0]: Copied! <pre>print(\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\")\n</pre> print(\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\") <p>Now, let's assign the data object storing string URL to the name <code>basemap</code>.</p> In\u00a0[\u00a0]: Copied! <pre>basemap = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\nprint(basemap)\n</pre> basemap = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\" print(basemap) <p>Calling <code>print()</code> on the variable name returns the data object that the variable name refers to.</p> <p>We can assign any Python objects to variable names. When the variable name is used in a Python statement, the data value which the variable points to is used in the operations.</p> In\u00a0[\u00a0]: Copied! <pre>x = 1\ny = 2\nz = x + y\nprint(z)\n</pre> x = 1 y = 2 z = x + y print(z) <p>Variables make a program's code easier to organise, write, and understand. We could have performed the above addition operation by just writing <code>1 + 2</code>. However, this doesn't provide us with a way to capture the result of that operation and use it again in our program without re-running <code>1 + 2</code>.</p> <p>Variables provide us with a mechanism by which we retrieve and use data objects (that are stored in the computer's memory) at various places in our program. A variable name points to the location in the computer's memory where a data object is stored.</p> <p>While using the result of <code>1 + 2</code> is a trivial example, there are many cases where using variables is important. This statement reads a CSV file into our Python program: <code>tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))</code>. To access the data stored in the CSV file we can use variable name <code>tmp_df</code> which points to where the data in the CSV file was loaded into memory. We don't need to read the CSV file from disk each time we want to access its data.</p> <p>Let's make these concepts concrete.</p> <p>When we assign the string <code>\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"</code> to the variable name <code>basemap</code>, the variable name is a pointer to the string's data object.</p> <p></p> <p>If we create another variable called <code>basemap_1</code> and assign it to <code>basemap</code>, both variables will point to the same data object (the string URL).</p> <p></p> <p>Let's check this.</p> In\u00a0[\u00a0]: Copied! <pre>basemap_1 = basemap\nprint(basemap_1)\n</pre> basemap_1 = basemap print(basemap_1) <p>If we assign a new data object to <code>basemap</code>, <code>basemap_1</code> will still point to the original string data.</p> <p></p> In\u00a0[\u00a0]: Copied! <pre>basemap = [1, 2, 3, 4, 5]\nprint(basemap)\nprint(basemap_1)\n</pre> basemap = [1, 2, 3, 4, 5] print(basemap) print(basemap_1) <p>If we assign <code>basemap_1</code> to a new data object the string data for URL will no longer be accessible in our program and will eventually be removed from the computer's memory.</p> In\u00a0[\u00a0]: Copied! <pre>print(\"this statement is executed first\")\nprint(\"and this statement is executed second\")\n</pre> print(\"this statement is executed first\") print(\"and this statement is executed second\") In\u00a0[\u00a0]: Copied! <pre>x = [1, 2, 3]\n\nfor i in x:\n    print(i + 10)\n</pre> x = [1, 2, 3]  for i in x:     print(i + 10) <p>It is important to note that the statements inside the for loop must be indented.</p> <p>Let's refer back to our program to read in crop yield data and see a use of for loops.</p> <pre># Combine the csv files into one data frame\ndfs = []\n\nfor i in harvester_data_files:\n    if i.endswith(\".csv\"):\n        print(f\"Loading file {i} into a Pandas DataFrame\")\n        tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))\n        dfs.append(tmp_df)\n</pre> <p>Here, the for loop is iterating over a list of file paths to CSV files storing crop yield data. For each of the CSV files in the list, the data is read into a variable <code>tmp_df</code> in turn, and, then appended to the list <code>dfs</code>. This is an example of how we can loop over a series of files in a folder on our computer and read their data into our Python program.</p> <p>Let's modify the for loop to illustrate this.</p> In\u00a0[\u00a0]: Copied! <pre># Load the canola yield data from the harvester\nharvester_data_path = os.path.join(os.getcwd(), \"week-1\")\n\n# Get a list of canola yield data\nharvester_data_files = os.listdir(harvester_data_path)\n\n# Check we have a list of csv files\nprint(harvester_data_files)\n\n# loop over elements in harvester_data_files\n# i takes on the value of a path to a csv file\nfor i in harvester_data_files: \n    if i.endswith(\".csv\"):\n        print(\" \")\n        print(\"**********************************************************\")\n        print(f\"We are currently loading file {i} into a Pandas DataFrame\")\n        tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))\n        print(tmp_df.head())\n        dfs.append(tmp_df)\n\nprint(\" \")\nprint(f\"We have a list of {len(dfs)} Pandas DataFrames read from csv files\")\n</pre> # Load the canola yield data from the harvester harvester_data_path = os.path.join(os.getcwd(), \"week-1\")  # Get a list of canola yield data harvester_data_files = os.listdir(harvester_data_path)  # Check we have a list of csv files print(harvester_data_files)  # loop over elements in harvester_data_files # i takes on the value of a path to a csv file for i in harvester_data_files:      if i.endswith(\".csv\"):         print(\" \")         print(\"**********************************************************\")         print(f\"We are currently loading file {i} into a Pandas DataFrame\")         tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))         print(tmp_df.head())         dfs.append(tmp_df)  print(\" \") print(f\"We have a list of {len(dfs)} Pandas DataFrames read from csv files\")    In\u00a0[\u00a0]: Copied! <pre>x = 11\n\nif x &gt;= 10:\n    print(\"x is greater than or equal to 10\")\n</pre> x = 11  if x &gt;= 10:     print(\"x is greater than or equal to 10\") In\u00a0[\u00a0]: Copied! <pre># nothing should be printed\nx = 9\n\nif x &gt;= 10:\n    print(\"x is greater than or equal to 10\")\n</pre> # nothing should be printed x = 9  if x &gt;= 10:     print(\"x is greater than or equal to 10\") <p>Similar to for loops, the statements inside the <code>if</code> block should be indented.</p> <p>We can use <code>else</code> blocks for statements that can be executed if the <code>if</code> statement evaluates to <code>False</code>.</p> <pre>x = 9\n\nif x &gt;= 10:\n    print(\"x is greater than or equal to 10\")\nelse:\n    print(\"x is less than 10\")\n</pre> In\u00a0[\u00a0]: Copied! <pre>x = 9\n\nif x &gt;= 10:\n    print(\"x is greater than or equal to 10\")\nelse:\n    print(\"x is less than 10\")\n</pre> x = 9  if x &gt;= 10:     print(\"x is greater than or equal to 10\") else:     print(\"x is less than 10\") <p>There are many uses for <code>if</code> statements in Python programs. An <code>if</code> statement was used when we read in CSV files of harvester data.</p> <pre># Combine the csv files into one data frame\ndfs = []\n\nfor i in harvester_data_files:\n    if i.endswith(\".csv\"):\n        print(f\"Loading file {i} into a Pandas DataFrame\")\n        tmp_df = pd.read_csv(os.path.join(harvester_data_path, i))\n        dfs.append(tmp_df)\n</pre> <p>Here, the <code>if</code> statement is being used to check the file path is referring to a CSV file. Only if this is <code>True</code> does our program try to read the file into a pandas <code>DataFrame</code>.</p> In\u00a0[\u00a0]: Copied! <pre>s = (1, 2, 3)\n# add code here #\n</pre> s = (1, 2, 3) # add code here # answer <pre>for i in s: \n    print(i - 3)\n</pre> How would you iterate over list of file paths? Using a for loop.  <p>Write a for loop to subtract 3 from every element in the tuple <code>s</code> and append the result to a list <code>q</code>?</p> In\u00a0[\u00a0]: Copied! <pre>q = []\ns = (1, 2, 3)\n# add code here #\n</pre> q = [] s = (1, 2, 3) # add code here # answer <pre>for i in s: \n    q.append(i - 3)\n\nprint(q)\n</pre> <p>Write a loop to subtract 3 from every element in the tuple <code>s</code> and append the result to a list <code>q</code> if the result is less than 0?</p> In\u00a0[\u00a0]: Copied! <pre>q = []\ns = (1, 2, 3)\n# add code here #\n</pre> q = [] s = (1, 2, 3) # add code here # answer <pre>for i in s:\n    if i -3 &lt; 0:\n        q.append(i - 3)\n\nprint(q)\n</pre> In\u00a0[\u00a0]: Copied! <pre># Load the canola yield data from the harvester\nharvester_data_path = os.path.join(os.getcwd(), \"week-1\", \"canola-yield-df-1.csv\")\n\ndf = pd.read_csv(harvester_data_path)\n\n# check that df is a DataFrame\ntype(df)\n</pre> # Load the canola yield data from the harvester harvester_data_path = os.path.join(os.getcwd(), \"week-1\", \"canola-yield-df-1.csv\")  df = pd.read_csv(harvester_data_path)  # check that df is a DataFrame type(df) In\u00a0[\u00a0]: Copied! <pre># Get the shape property of the DataFrame\ndf.shape\n</pre> # Get the shape property of the DataFrame df.shape <p>A tuple data structure is used to store the <code>shape</code> property of a <code>DataFrame</code>.</p> In\u00a0[\u00a0]: Copied! <pre># Get the values of the DataFrame\ndf.values\n</pre> # Get the values of the DataFrame df.values <p>The <code>DataFrame</code> referenced by <code>df</code> has an <code>info()</code> method. Let's use it.</p> In\u00a0[\u00a0]: Copied! <pre># Load the canola yield data from the harvester\nharvester_data_path = os.path.join(os.getcwd(), \"week-1\", \"canola-yield-df-1.csv\")\n\ndf = pd.read_csv(harvester_data_path)\n\ndf.info()\n</pre> # Load the canola yield data from the harvester harvester_data_path = os.path.join(os.getcwd(), \"week-1\", \"canola-yield-df-1.csv\")  df = pd.read_csv(harvester_data_path)  df.info() <p>The <code>info()</code> method has printed out a summary of the <code>DataFrame</code> for us. A <code>DataFrame</code> also has a <code>mean()</code> method to quickly compute the average of values in a column.</p> In\u00a0[\u00a0]: Copied! <pre>df.mean(numeric_only=True)\n</pre> df.mean(numeric_only=True) <p>You will notice that we passed <code>numeric_only=True</code> when using the <code>mean()</code> method. Head the the mean() documentation to see what this does.</p> In\u00a0[\u00a0]: Copied! <pre>farm_name = \"my farm\"\n# uncomment below to see string methods\n# farm_name.&lt;press_tab&gt;\n</pre> farm_name = \"my farm\" # uncomment below to see string methods # farm_name. In\u00a0[\u00a0]: Copied! <pre>a_list = [1, 2, 3]\n# uncomment below to see list methods\n# a_list.&lt;press_tab&gt;\n</pre> a_list = [1, 2, 3] # uncomment below to see list methods # a_list. In\u00a0[\u00a0]: Copied! <pre>harvester_data_path = os.path.join(os.getcwd(), \"data\", \"week-1\", \"canola-yield-df-1.csv\")\nprint(harvester_data_path)\n</pre> harvester_data_path = os.path.join(os.getcwd(), \"data\", \"week-1\", \"canola-yield-df-1.csv\") print(harvester_data_path) <p>Inside the <code>os.path.join()</code> function you will see that we use the <code>os.getcwd()</code> method from the os module. This returns the current working directory.</p> In\u00a0[\u00a0]: Copied! <pre>os.getcwd()\n</pre> os.getcwd() <p>You will see that we imported pandas as <code>pd</code>. This means we can refer to pandas as <code>pd</code> in our script. For example, to access the <code>read_csv()</code> function we write <code>pd.read_csv()</code> and not <code>pandas.read_csv()</code>. This is just a convenience to make the script less cluttered. The following would also be valid.</p> <pre>import pandas\ndf = pandas.read_csv(\"file.csv\")\n</pre>"},{"location":"notebooks/week-1_2/#introduction","title":"Introduction\u00b6","text":"<p>This lab will provide an introduction to programming concepts in Python. The concepts this lab will cover are:</p> <ul> <li>data types and structures</li> <li>variables and bindings</li> <li>control flow, loops, and conditional execution</li> <li>classes and objects</li> </ul> <p>This lab will start by running a short Python program that loads some crop yield data collected by harvesters from disk and visualises this data on interactive maps and charts. We will then work through the program exploring how it uses a range of Python programming concepts to complete its task.</p>"},{"location":"notebooks/week-1_2/#setup","title":"Setup\u00b6","text":""},{"location":"notebooks/week-1_2/#run-the-labs","title":"Run the labs\u00b6","text":"<p>You can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you're working with Google Colab be aware that your sessions are temporary and, if required, you'll need to take care to save, backup, and download your work.</p>"},{"location":"notebooks/week-1_2/#download-data","title":"Download data\u00b6","text":"<p>If you need to download the date for this lab, run the following code snippet.</p>"},{"location":"notebooks/week-1_2/#install-packages","title":"Install packages\u00b6","text":"<p>If you're working in Google Colab, you'll need to install the required packages that don't come with the colab environment.</p>"},{"location":"notebooks/week-1_2/#import-modules","title":"Import modules\u00b6","text":"<p>We'll introduce modules in detail later. But, for now, modules are collections of Python data structures and functions that we can <code>import</code> and use in our program. For example, pandas provides a <code>DataFrame</code> structure for storing tabular data and specific functions for working with tabular data. Plotly Express <code>plotly.express</code> provides functions for generating visualisations, importing Plotly Express means we don't need to write our own code to generate visualisations, we can just use existing functions which makes our lives easier.</p>"},{"location":"notebooks/week-1_2/#a-first-python-program","title":"A first Python program\u00b6","text":"<p>Python is a programming language.</p>"},{"location":"notebooks/week-1_2/#programs","title":"Programs\u00b6","text":"<ul> <li>A program is a series of statements that are executed to complete a task</li> <li>Programs complete tasks by loading, transforming, and visualising data</li> <li>Data in programs can be of different types (numeric, text, boolean)</li> <li>Data can be combined into data structures to represent complex concepts and objects</li> <li>Functions operate on data to complete tasks</li> </ul> Detailed notes on Python programs <p>As stated above, a program is a series of statements that are executed to complete a task. The ultimate goal of the program here is to generate visualisations of crop yield data recorded by harvesters. However, to achieve this the program consists of a series of sub-tasks that include reading the harvester data from CSV files on disk, inspecting the data, transforming it to a spatial data structure, and then rendering web maps and charts.</p> <p>Our program is loading, transforming, and visualising data. This means our program needs to be able store and represent different types and structures of data. If you look in the display of the <code>DataFrame</code> there are numeric, text, and date type data in the columns. Python provides tools for representing different types of data and structures for combining data to represent more complex concepts. For example, the <code>DataFrame</code> that is displayed is a data structure well suited to storing tabular data.</p> <p>In short, a Python program stores data as objects and then uses this data in a range functions that operate on this data to complete tasks.</p> <p></p> <p>Here, a short Python program is demonstrated that:</p> <ol> <li>reads in crop yield data collected by a harvester in Western Australia's Wheatbelt</li> <li>converts the data into a spatial format</li> <li>visualises the data on a web map and charts</li> </ol>"},{"location":"notebooks/week-1_2/#import-modules","title":"Import modules\u00b6","text":"<p>We'll introduce modules in detail later. But, for now, modules are collections of Python tools that we can <code>import</code> and use in our program. For example, pandas provides a <code>DataFrame</code> structure for storing tabular data and specific functions for working with tabular data. Plotly Express <code>plotly.express</code> provides functions for generating visualisations, importing Plotly Express means we don't need to write our own code to generate visualisations, we can just use existing functions which makes our lives easier.</p>"},{"location":"notebooks/week-1_2/#recap-quiz","title":"Recap quiz\u00b6","text":"In a Python program, are data types just used to store observations of scientific variables such as crop yield or temperature? <p>No. In a Python program built-in data types are used to store a range of information relevant to the execution of a program. This could include \"scientific\" data such as an array of crop yield values. However, data in a Python program could refer to file paths and directory structures, URLs to websites or data stored in the cloud, or credentials to log in to databases.</p> <p></p> <p>In this lab we will break down the Python program that generates visualisations of crop yield data recorded by harvesters into its fundamental building blocks, identify how different types of data are represented in Python programs, and demonstrate how we can do things with this data to produce useful outputs.</p>"},{"location":"notebooks/week-1_2/#computational-thinking","title":"Computational thinking\u00b6","text":"<p>A useful skill to develop when writing or analysing Python programs is computational thinking. This refers to breaking a larger task down into small sub-tasks (and possibly breaking sub-tasks into sub-tasks). Often, it is easier to reason with smaller more focused tasks than to grapple with a large complex problem as a whole.</p> <p>A good homework exercise to help build your understanding of Python concepts is to work through the program above and break it down into series of smaller tasks (e.g. find csv files, read in csv data, make data spatial)</p>"},{"location":"notebooks/week-1_2/#statements-and-comments","title":"Statements and comments\u00b6","text":"<p>A Python program consists of statements. A Python statement is a line of Python code which can be executed by the computer.</p> <p>A comment is a line of text that starts with the <code>#</code> symbol. It is not executed by the computer. We can use comments to make notes in our script to help us understand what the program is trying to achieve.</p> <p>For example, this code snippet contains two comments and one statement:</p> <pre># Inspect the yield data format\n# Display the first n rows\ndf.head()\n</pre>"},{"location":"notebooks/week-1_2/#objects","title":"Objects\u00b6","text":"<p>Everything in a Python program is an object. Built-in scalar data types are the most fundamental building blocks of a Python program. We can use these scalar data types to represent single numbers, words, and sentences. This is where we'll start unpicking this Python program.</p>"},{"location":"notebooks/week-1_2/#data-types","title":"Data types\u00b6","text":"<p>Python programs perform operations on data to complete tasks. This can be scientific data such as crop yield or temperature measurements or it can be other forms of data necessary for the program to execute such as a file path to where data is stored on disk.</p>"},{"location":"notebooks/week-1_2/#built-in-data-types","title":"Built-in data types\u00b6","text":"<p>Python comes with built-in data types that can be used to store different values. These are sometimes called scalar types as they store single values.</p> <ul> <li><code>float</code> - storing floating point numeric values.</li> <li><code>int</code> - storing integer numeric values.</li> <li><code>str</code> - storing text data as strings.</li> <li><code>bool</code> - storing <code>True</code> or <code>False</code> as boolean values.</li> <li><code>None</code> - storing null values.</li> <li><code>bytes</code> - storing raw binary data.</li> </ul>"},{"location":"notebooks/week-1_2/#numeric-data-types","title":"Numeric data types\u00b6","text":"<p><code>int</code> and <code>float</code> are numeric data types in Python and are used to store integer and floating point values, respectively.</p> <p>The canola yield data that we have imported is of numeric type with units of tonnes/ha. Let's represent a crop yield measurement of 0.227 tonnes/ha as data in our program and inspect its type.</p>"},{"location":"notebooks/week-1_2/#string-data-types","title":"String data types\u00b6","text":"<p>We also need to represent text data in our programs. In the crop yield dataset the sample id is text. In Python, text data is stored as a <code>str</code> type (or string type).</p> <p>Text data is stored as string types by enclosing the characters in double<code>\"</code> or single <code>'</code> quotes.</p>"},{"location":"notebooks/week-1_2/#boolean-data-types","title":"Boolean data types\u00b6","text":"<p>Boolean (<code>bool</code>) data types are used for storing <code>True</code> or <code>False</code> values. In Python, <code>True</code> or <code>False</code> are Boolean values and not string data types.</p> <p>Boolean data types are used to store the result of testing a condition that evaluates to true or false. For example, greater than and less than operations evaluate to true or false. We could test if our crop yield value of 0.227 is greater than 0.2 (it is and this expression should evaluate to true).</p>"},{"location":"notebooks/week-1_2/#recap-quiz","title":"Recap quiz\u00b6","text":"If you execute <code>x = 3.4</code>, what data type will <code>x</code> be? <code>float</code> Which data type would be most suited to record the number of apples harvested from an orchard? <code>int</code> -  we should not be able to harvest fractions of apples.  Which data type would we use to record a farm name? <code>str</code> - assuming the farm name is text data.  <code>y = 4 + 5</code> and <code>z = y &gt; 10</code> - what value will <code>z</code> be? <code>False</code> - <code>y</code> evaluates to 9 which is less than 10. Therefore, <code>z</code> will be <code>False</code> and of <code>bool</code> type."},{"location":"notebooks/week-1_2/#data-structures","title":"Data structures\u00b6","text":"<p>Python provides a series of built-in data structures that can be used to group together and store related data.</p> <p>Data structures can be used to model a range of practical and real-world problems or phenomenon by combining simple data types. For example, we could use a collection of numeric data to represent a time-series of precipitation, string data to represent the weather station name, and combine string and numeric data together in a data structure to create a bespoke weather station data structure.</p> <ul> <li><code>list</code> - a variable length collection of objects that can be modified</li> <li><code>tuple</code> - a fixed length collection of objects that cannot be modified</li> <li><code>set</code> - a collection of unique objects</li> <li><code>dict</code> - a collection of objects stored as key:value pairs</li> </ul>"},{"location":"notebooks/week-1_2/#lists","title":"Lists\u00b6","text":"<p>Lists in Python:</p> <ul> <li>can be modified during a program's execution</li> <li>can store duplicate values</li> <li>are created by placing elements in square brackets <code>[]</code></li> <li>elements of a list are ordered</li> <li>elements of a list can be of different data types</li> </ul> <p>We could store the sample names in our crop yield data set as a list:</p>"},{"location":"notebooks/week-1_2/#indexing-in-python","title":"Indexing in Python\u00b6","text":"<ul> <li>An index is an element's location within a data structure</li> <li>Often, in Python, elements are accessed by their index position using the square brackets operator and passing an index in as an argument (e.g. the first element of <code>x</code> is <code>x[0]</code>)</li> <li>In Python, indexing starts at 0 - this means the index for the first element in a data structure is 0</li> <li>It is important to become familiar with the concept of indexing - you will use it often as you handle data in Python</li> </ul> <p>Let's demonstrate this by accessing the elements of the <code>sample_id_list</code> we created above.</p>"},{"location":"notebooks/week-1_2/#tuples","title":"Tuples\u00b6","text":"<p>Tuple in Python:</p> <ul> <li>elements are unchangeable (immutable)</li> <li>tuple elements are ordered</li> <li>store a fixed-length number of elements</li> <li>created by placing Python objects inside parentheses <code>()</code></li> </ul>"},{"location":"notebooks/week-1_2/#sets","title":"Sets\u00b6","text":"<p>Set in Python:</p> <ul> <li>unordered collection objects</li> <li>set elements cannot be duplicated</li> <li>sets are immutable</li> <li>sets are created by placing elements inside curly brackets <code>{}</code></li> </ul> <p>Let's create a set and demonstrate that it cannot store duplicate values.</p>"},{"location":"notebooks/week-1_2/#dictionary-objects","title":"Dictionary objects\u00b6","text":"<p>Dictionary objects, or <code>dict</code> objects:</p> <ul> <li>store data as a collection of key:value pairs</li> <li>Dictionary objects can be changed and modified</li> <li>Dictionary object elements are ordered</li> <li>We can access dictionary elements by their key</li> <li>Dictionary objects are created by placing key:value pairs inside curly brackets <code>{}</code></li> <li>Keys of a dictionary object cannot be duplicated</li> <li>Elements (values) of dictionary objects can be of a different type</li> <li>Values can be of different lengths</li> </ul>"},{"location":"notebooks/week-1_2/#using-dictionary-objects-to-represent-tabular-data","title":"Using Dictionary objects to represent tabular data\u00b6","text":"<p>Tabular data has data values stored in rows and columns. Generally, a column corresponds to a particular variable or type of data and rows correspond to observed or measured values. We can use dictionary objects to represent tabular data in Python.</p> <p>For example, we can use the key:value pair pattern to represent a column header and column values.</p> <pre>\"Elevation(m)\": [213, 222, 214, 254]\n</pre> <p>Here, we've used a string object to represent the column header (the key) and a list object to represent column values (the value). Combining one or more key:value pairs in a dictionary object is a way of representing tabular data in Python.</p> <pre>{\n\"Elevation(m)\": [213, 222, 214, 254],\n\"Date\": [\"20/11/2017\", \"20/11/2017\", \"20/11/2017\", \"19/11/2017\"],\n\"sample_id\": [\"bf66_sample_1\", \"bf66_sample_1\", \"bf66_sample_2\", \"bf66_sample_3\"]\n}\n</pre> <p>Let's create this dictionary object.</p>"},{"location":"notebooks/week-1_2/#recap-quiz","title":"Recap quiz\u00b6","text":"<code>x = [1, 2, 3, 4]</code> - what data structure is <code>x</code>? List  <code>q = {1, 2, 3, 4}</code> - what data structure is <code>q</code>? Set  Which data structure organises its elements using key:value pairs? Dictionary objects  Are lists immutable data structures? No, we can modify the values of a list and change its size (number of elements) during the program's execution."},{"location":"notebooks/week-1_2/#variables","title":"Variables\u00b6","text":"<p>In the program to read in and visualise crop yield data, you will have noticed this syntax pattern: <code>variable_name = data</code>.</p> <pre>basemap = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\n</pre> <p><code>=</code> is the assignment operator (not equals) which is assigning (or binding) the <code>variable_name</code> to the <code>data</code> object.</p> <p>The statement <code>basemap = \"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"</code> is assigning the data <code>\"https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"</code> to the variable name <code>basemap</code>. The data is string which is storing the URL for a satellite imagery basemap.</p> <p>Let's see what the data looks like.</p>"},{"location":"notebooks/week-1_2/#variable-names","title":"Variable names\u00b6","text":"<p>There are rules that need to be followed when creating variable names:</p> <ul> <li>variable names can only be text letters (A-Z, a-z), numbers (0-9), or underscores (_)</li> <li>variable names cannot begin with a number</li> <li>variable names cannot include whitespace</li> <li>variable names cannot be reserved keywords such True, False, if</li> </ul> <p>There are also some conventions that can be followed to help write programs that are easy to follow:</p> <ul> <li>use a consistent style for writing variable names - snake_case where words are separated by underscores is recommended by the PEP8 style guide for Python code</li> <li>use a descriptive variable name so it helps you understand what kind of data it is referring to</li> </ul>"},{"location":"notebooks/week-1_2/#control-flow","title":"Control flow\u00b6","text":"<p>So far we have demonstrated how we can represent information and concepts in our program as different data types and using different data structures. However, we are not using our program as a data storage device. We are using it to complete tasks with this data.</p> <p>Control flow refers to the sequence of steps that our program takes from start to finish when it is run.</p> <p>The most simple form of control flow is executing statements from top to bottom as they are written in your script.</p>"},{"location":"notebooks/week-1_2/#loops","title":"Loops\u00b6","text":"<p>Loops use a <code>for</code> statement that allows us to iterate over items in a sequence. For example, if <code>x</code> is a list <code>[1, 2, 3]</code> then:</p> <pre>for i in x:\n    print(i)\n</pre> <p>will print the values of 1, 2, and 3 in turn for each iteration of the loop, <code>i</code>, takes on the value of the corresponding element in <code>x</code>.</p> <p>For loops are useful if we want to iterate over (repeat) a block of statements using different values from a sequence of items in turn. If we wanted to add 10 to each element of <code>x</code> we could write a for loop as:</p> <pre>for i in x:\n    print(i + 10)\n</pre> <p>Let's demonstrate this.</p>"},{"location":"notebooks/week-1_2/#conditional-execution","title":"Conditional execution\u00b6","text":"<p>Conditional execution is a form of control flow that allows for branches in the sequence that statements are executed. A boolean condition is tested, and, <code>if</code> it evaluates to <code>True</code> then one set of statements are executed and <code>if</code> it evaluates to <code>False</code> a different set of statements are executed.</p> <p>Conditions are tested within <code>if</code> blocks:</p> <pre>if True:\n    these statements are executed\nelse:\n    these statements are executed\n</pre> <p>A simple example:</p> <pre>x = 11\n\nif x &gt;= 10:\n    print(\"x is greater than or equal to 10\")\n</pre> <p>In this instance, the statements inside the <code>if</code> block will be executed as <code>x</code> is 11 and so greater than 10.</p> <p>However, if we change the value of x to 9 the statements inside the <code>if</code> block will not be executed.</p> <pre>x = 9\n\nif x &gt;= 10:\n    print(\"x is greater than or equal to 10\")\n</pre>"},{"location":"notebooks/week-1_2/#recap-quiz","title":"Recap quiz\u00b6","text":"<p>Write a for loop to subtract 3 from every element in a tuple <code>s</code> and print the result?</p>"},{"location":"notebooks/week-1_2/#classes-and-objects","title":"Classes and Objects\u00b6","text":"<p>We have mentioned a few times that Python programs comprise objects. We will now define what an object is and how the concept of an object relates to the data types and structures we have looked at above.</p>"},{"location":"notebooks/week-1_2/#objects","title":"Objects\u00b6","text":"<p>An object is a more general concept in programming. An object in a computer program has:</p> <ul> <li>properties or attributes (data)</li> <li>behaviour (methods or functions that do things with object data).</li> </ul> <p>Objects provide a way to add structure to a program by combining related data and behaviours.</p> <p>Alongside the built-in data types and structures, we can create objects that are customised and useful for specific tasks or representing specific kinds of data or real-world problems. Often, custom data types will combine the built-in data types and structures, or other custom objects, to create objects that represent more complex concepts.</p>"},{"location":"notebooks/week-1_2/#classes","title":"Classes\u00b6","text":"<p>A class is a definition of an object. The class defines the object's data and methods. An object is an instance of a class in our programs.</p> <p>An object's data (sometimes called its properties or attributes) can be built-in Python data types or structures or custom classes. An object's methods are functions that can be used to transform data or implement other behaviour that is relevant to the object. For example, an object representing a table is more complex than a list.</p>"},{"location":"notebooks/week-1_2/#pandas-dataframes","title":"pandas <code>DataFrame</code>s\u00b6","text":"<p>For most use cases there are existing classes that have already been developed and can be used in our programs. Keeping with the idea of working with tabular data, pandas provides a <code>DataFrame</code> class to work with tabular data. In our Python program to visualise the crop yield data we read the tabular data stored in CSV files into pandas <code>DataFrames</code>.</p> <p>A pandas <code>DataFrame</code> is a far more comprehensive class for handling tabular data. Compared to our small example of using a dictionary object to store tabular data, a pandas <code>DataFrame</code> implements well defined data structures for tabular data and provides a suite of useful methods (functions) for analysing and processing tabular data.</p>"},{"location":"notebooks/week-1_2/#dataframe-properties","title":"<code>DataFrame</code> Properties\u00b6","text":"<p>The class <code>DataFrame</code> is a data structure for \"Two-dimensional, size-mutable, potentially heterogeneous tabular data\". It has the following properties:</p> <ul> <li>data - the tabular data stored in the data frame</li> <li>index - the row index (row labels)</li> <li>columns - the column headers</li> <li>dtype - the data types of each column</li> </ul> <p></p> <p>A pandas <code>DataFrame</code> stores its values in rows and columns. There is a list of column headers (which should provide a helpful description of what kind of data is in each column) and a row index.</p> <p>The values in columns are pandas <code>Series</code> objects. A <code>Series</code> is an array of the same type data.</p> <p>The pandas <code>DataFrame</code> object stores a range of properties that are useful for working with tabular data. You can look up the documentation for a <code>DataFrame</code> here. The properties listed do not have parentheses after their name <code>()</code>. Let's look at the properties under attributes and underlying data. We can see the <code>DataFrame</code> has a <code>values</code> property which is the actual data values in the table and a <code>shape</code> property which tells us the shape of the table (number of rows and columns).</p> <p></p> <p>Most of the time we will explore classes using their documentation websites. Let's read a CSV file into a pandas <code>DataFrame</code> and explore its properties.</p>"},{"location":"notebooks/week-1_2/#dataframe-methods","title":"<code>DataFrame</code> methods\u00b6","text":"<p>However, a <code>DataFrame</code> is more than just an object for storing data. It is also where we can find a wide range of functions for working with tabular data - the class methods. Go back to the documentation for a <code>DataFrame</code> here. The <code>DataFrame</code> methods are indicated by the parentheses after their name <code>()</code>.</p> <p>There are methods to help us inspect the <code>DataFrame</code> values. The <code>info()</code> method prints a concise summary table of the <code>DataFrame</code>, there a range of methods for performing mathemtatical computations / descriptive stats, and methods for reading data on disk into <code>DataFrame</code>s.</p> <p>Let's explore how we can use some of these methods to work with tabular data in <code>DataFrames</code>.</p>"},{"location":"notebooks/week-1_2/#methods-and-functions","title":"Methods and functions\u00b6","text":"<p>Functions are executed to perform a task using data. You can spot functions by <code>()</code> appearing after the function name. Functions can take input data - this is the function's arguments -  and use these inputs to complete it's task.</p> <p>Functions can return data back to the Python program, display data on your screen, or save data to disk.</p> <p>For example, the <code>print()</code> function takes data as an argument and prints it on your display as text. For example, <code>print(\"hello\")</code> would print <code>hello</code> on your screen. The <code>df = pd.read_csv(\"a_csv_file.csv\")</code> is a function within the pandas package the takes in a path to a CSV file as an argument and reads the data from that file into a <code>DataFrame</code> referenced by <code>df</code>.</p> <p>Methods are functions that belong to a class. For example, the <code>mean()</code> method of the pandas <code>DataFrame</code> can be called by accessing it via a <code>DataFrame()</code> object (e.g <code>df.mean()</code>). Methods often provide functionality related to the \"topic\" of the class they're associated with. For example, <code>DataFrame</code> methods provide functions related to working tabular data in <code>DataFrame</code> objects; dictionary objects have specialist methods geared for retrieving and setting data elements in dictionaries; string objects have methods for manipulating text (e.g. the <code>lower()</code> of a string object will convert all text characters to lower case).</p> <p>The general pattern for executing a function / method is:</p> <ol> <li>The function is called and any data are passed in as arguments inside <code>()</code></li> <li>The function performs operations on the data passed in</li> <li>The function returns the result of operating on the data</li> </ol> <p>As everything in Python is an object, lists and string objects have methods. You can see the methods associated with an object by typing the object name, dot operator, and pressing tab.</p> <p>For example, if <code>farm_name = \"my farm\"</code>, <code>farm_name.&lt;press_tab&gt;</code> will print a list of string object methods.</p> <p>Try this below and explore string and list methods, and how they can be used to transform your data.</p>"},{"location":"notebooks/week-1_2/#instances","title":"Instances\u00b6","text":"<p>Above we said that a class is a definition of an object. The class never has any data stored in it or executes any of its methods - it's just a template for a particular type of object. Objects are instances of a class.</p> <p>When we executed the statement <code>df = pd.read_csv(\"csv_file.csv\")</code> we are creating an instance object of the <code>DataFrame</code> class which is stored in the computer's memory.</p>"},{"location":"notebooks/week-1_2/#dot-notation","title":"Dot notation\u00b6","text":"<p>We use the <code>.</code> operator to access properties and methods of class. For example to access the <code>shape</code> property of a <code>DataFrame</code> we write <code>df.shape</code> and to access the <code>info()</code> method we write <code>df.info()</code>.</p>"},{"location":"notebooks/week-1_2/#modules","title":"Modules\u00b6","text":"<p>There is one final concept to cover that is used in our program to read and visualise harvester yield data. The very first lines of the program.</p> <pre># Import modules\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\n</pre> <p>Here, we are importing modules into our script.  A module is a Python file (a file with a <code>.py</code> ending) that contains class definitions and functions. When we import a module into our program we can use the classes defined in the module.</p> <p>For example, we have used the method <code>os.path.join()</code> from the os module in our program. This function takes string data describing parts of a file path and joins them together to create path to a directory or file.</p>"},{"location":"notebooks/week-2_1/","title":"Week 2 1","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport subprocess\n\nif \"data_lab-2_1\" not in os.listdir(os.getcwd()):\n    subprocess.run('wget \"https://github.com/geog3300-agri3003/lab-data/raw/main/data_lab-2_1.zip\"', shell=True, capture_output=True, text=True)\n    subprocess.run('unzip \"data_lab-2_1.zip\"', shell=True, capture_output=True, text=True)\n    if \"data_lab-2_1\" not in os.listdir(os.getcwd()):\n        print(\"Has a directory called data_lab-2_1 been downloaded and placed in your working directory? If not, try re-executing this code chunk\")\n    else:\n        print(\"Data download OK\")\n</pre> import os import subprocess  if \"data_lab-2_1\" not in os.listdir(os.getcwd()):     subprocess.run('wget \"https://github.com/geog3300-agri3003/lab-data/raw/main/data_lab-2_1.zip\"', shell=True, capture_output=True, text=True)     subprocess.run('unzip \"data_lab-2_1.zip\"', shell=True, capture_output=True, text=True)     if \"data_lab-2_1\" not in os.listdir(os.getcwd()):         print(\"Has a directory called data_lab-2_1 been downloaded and placed in your working directory? If not, try re-executing this code chunk\")     else:         print(\"Data download OK\") In\u00a0[\u00a0]: Copied! <pre># Import modules\nimport os\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nimport numpy as np\nimport plotly.io as pio\n\n# setup renderer\nif 'google.colab' in str(get_ipython()):\n    pio.renderers.default = \"colab\"\nelse:\n    pio.renderers.default = \"jupyterlab\"\n</pre> # Import modules import os import pandas as pd import geopandas as gpd import plotly.express as px import numpy as np import plotly.io as pio  # setup renderer if 'google.colab' in str(get_ipython()):     pio.renderers.default = \"colab\" else:     pio.renderers.default = \"jupyterlab\" In\u00a0[\u00a0]: Copied! <pre># Load the crop yield data\ncrop_yield_data_path = os.path.join(os.getcwd(), \"data_lab-2_1\")\n\n# Read the canola and wheat crop yield data\ncanola_fpath = os.path.join(crop_yield_data_path, \"bf66-canola-yield-max-vi_sampled.geojson\")\ncanola_gdf = gpd.read_file(canola_fpath)\nwheat_fpath = os.path.join(crop_yield_data_path, \"bf66-wheat-yield-max-vi_sampled.geojson\")\nwheat_gdf = gpd.read_file(wheat_fpath)\n\n# Combine (stack) the geojson files into one GeoDataFrame\ngdf = pd.concat([canola_gdf, wheat_gdf], axis=0)\ngdf.head()\n</pre> # Load the crop yield data crop_yield_data_path = os.path.join(os.getcwd(), \"data_lab-2_1\")  # Read the canola and wheat crop yield data canola_fpath = os.path.join(crop_yield_data_path, \"bf66-canola-yield-max-vi_sampled.geojson\") canola_gdf = gpd.read_file(canola_fpath) wheat_fpath = os.path.join(crop_yield_data_path, \"bf66-wheat-yield-max-vi_sampled.geojson\") wheat_gdf = gpd.read_file(wheat_fpath)  # Combine (stack) the geojson files into one GeoDataFrame gdf = pd.concat([canola_gdf, wheat_gdf], axis=0) gdf.head() <p>Displaying the <code>head</code> of the <code>GeoDataFrame</code> <code>gdf</code> demonstrates that we are working with tabular data. There is a <code>geometry</code> column,  which stores the geographic location that each row in the table's attributes correspond to. Other columns of note are:</p> <ul> <li><code>DryYield</code> - crop yield values for each location (tonnes / ha)</li> <li><code>Variety</code> - 43Y23 RR indicates canola  ninja indicates wheat</li> <li><code>gndvi</code> - green normalised difference vegetation index, a satellite derived measure of greenness</li> <li><code>ndyi</code> - normalised difference yellowness index, a satellite derived measure of yellowness</li> </ul> In\u00a0[\u00a0]: Copied! <pre>fig = px.histogram(\n    data_frame=gdf, \n    x=\"DryYield\", \n    color=\"Variety\", \n    marginal=\"box\", \n    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\nfig.show()\n</pre> fig = px.histogram(     data_frame=gdf,      x=\"DryYield\",      color=\"Variety\",      marginal=\"box\",      hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"]) fig.show() <p>There are more options that you can use to configure a histogram here.</p> In\u00a0[\u00a0]: Copied! <pre>## ADD CODE HERE ##\n</pre> ## ADD CODE HERE ## answer <pre>fig = px.histogram(\n    data_frame=gdf, \n    x=\"DryYield\", \n    color=\"Variety\", \n    marginal=\"box\", \n    range_x=[0, 7],\n    hover_data=[\"DryYield\", \"Elevation\", \"WetMass\"])\nfig.show()\n</pre> <p>Let's have a go at generating a scatter plot to consolidate our understanding of how to map variables in our data to elements of a graphic. The documentation for scatter plots is here and you should notice similarities in how we set up a scatter plot to a histogram.</p> <p>Let's use a scatter plot to see if there is a relationship beetween crop yield and elevation. We are plotting two variables here so we need to use the <code>y</code> parameter to specify what column in our <code>GeoDataFrame</code> will be mapped onto the y-axis.</p> <p>We can use the <code>marginal_x</code> and <code>marginal_y</code> parameters to attach plots to the x- and y-axes that show the distributions of variables mapped to each axis.</p> <p>Finally, we're going to use the <code>opacity</code> argument here to make the point elements on the figure semi-transparent; this will help reveal more information about the density of data values.</p> <p>Both canola and wheat crop yield data is displayed. To see the relationship between one crop type's yield and elevation, click on the variety in the legend.</p> In\u00a0[\u00a0]: Copied! <pre>fig = px.scatter(\n    data_frame=gdf, \n    x=\"DryYield\", \n    y=\"Elevation\", \n    color=\"Variety\", \n    opacity=0.25, \n    marginal_x=\"box\", \n    marginal_y=\"violin\")\nfig.show()\n</pre> fig = px.scatter(     data_frame=gdf,      x=\"DryYield\",      y=\"Elevation\",      color=\"Variety\",      opacity=0.25,      marginal_x=\"box\",      marginal_y=\"violin\") fig.show() In\u00a0[\u00a0]: Copied! <pre>## ADD CODE HERE ##\n</pre> ## ADD CODE HERE ## answer <pre>fig = px.scatter(\n    data_frame=gdf, \n    x=\"DryYield\", \n    y=\"Elevation\", \n    color=\"Variety\", \n    range_x=[0,10],\n    opacity=0.25,\n    marginal_y=\"violin\")\nfig.show()\n</pre> In\u00a0[\u00a0]: Copied! <pre>fig = px.scatter(\n    data_frame=gdf, \n    x=\"gndvi\", \n    y=\"DryYield\", \n    color=\"Variety\", \n    opacity=0.05, \n    range_y=[0.1, 6], \n    range_x=[0.3, 0.9], \n    marginal_x=\"box\", \n    marginal_y=\"box\", \n    trendline=\"ols\"\n)\nfig.show()\n</pre> fig = px.scatter(     data_frame=gdf,      x=\"gndvi\",      y=\"DryYield\",      color=\"Variety\",      opacity=0.05,      range_y=[0.1, 6],      range_x=[0.3, 0.9],      marginal_x=\"box\",      marginal_y=\"box\",      trendline=\"ols\" ) fig.show() In\u00a0[\u00a0]: Copied! <pre>fig = px.scatter(\n    data_frame=gdf, \n    x=\"ndyi\", \n    y=\"DryYield\", \n    facet_col=\"Variety\", \n    opacity=0.05, \n    range_y=[0.1, 5], \n    range_x=[0.1, 0.6], \n    trendline=\"ols\"\n)\nfig.show()\n</pre> fig = px.scatter(     data_frame=gdf,      x=\"ndyi\",      y=\"DryYield\",      facet_col=\"Variety\",      opacity=0.05,      range_y=[0.1, 5],      range_x=[0.1, 0.6],      trendline=\"ols\" ) fig.show() In\u00a0[\u00a0]: Copied! <pre>fig = px.colors.sequential.swatches_continuous()\nfig.show()\n</pre> fig = px.colors.sequential.swatches_continuous() fig.show() <p>Let's use a sequential colour palette to visualise monthly precipitation over the field since 1981. The precipitation data is obtained from the TerraClimate: Monthly Climate and Climatic Water Balance for Global Terrestrial Surfaces dataset.</p> <p>Use the pandas <code>read_csv()</code> function to read in the precipitation data. Inside the <code>CSV</code> file each row represents a month-year combination and stores a monthly precipitation total in mm.</p> In\u00a0[\u00a0]: Copied! <pre># visualise monthly precipitation using a diverging palette\nclimate_data_path = os.path.join(os.getcwd(), \"data_lab-2_1\")\nprecip_df = pd.read_csv(os.path.join(climate_data_path, \"bf66-terra-precip-monthly.csv\"))\nprecip_df[\"month\"] = precip_df[\"month\"].astype(str)\nprecip_df[\"year\"] = precip_df[\"year\"].astype(str)\nprecip_df.head()\n</pre> # visualise monthly precipitation using a diverging palette climate_data_path = os.path.join(os.getcwd(), \"data_lab-2_1\") precip_df = pd.read_csv(os.path.join(climate_data_path, \"bf66-terra-precip-monthly.csv\")) precip_df[\"month\"] = precip_df[\"month\"].astype(str) precip_df[\"year\"] = precip_df[\"year\"].astype(str) precip_df.head() <p>We can create a heatmap to visualise monthly precipitation across time and using a colour palette where darker blue shades indicate wetter months. Note how we pass in the colour palette <code>Blues</code> as an argument to the <code>color_continuous_scale</code> parameter.</p> In\u00a0[\u00a0]: Copied! <pre>fig = px.density_heatmap(\n    precip_df,\n    x=\"year\", \n    y=\"month\", \n    z=\"pr\", \n    histfunc=\"sum\",\n    nbinsy=12,\n    color_continuous_scale=\"Blues\",\n    range_color=(0, 75),\n)\nfig.show()\n</pre> fig = px.density_heatmap(     precip_df,     x=\"year\",      y=\"month\",      z=\"pr\",      histfunc=\"sum\",     nbinsy=12,     color_continuous_scale=\"Blues\",     range_color=(0, 75), ) fig.show() In\u00a0[\u00a0]: Copied! <pre>## ADD CODE HERE\n</pre> ## ADD CODE HERE answer <pre>fig = px.density_heatmap(\n    precip_df,\n    x=\"year\", \n    y=\"month\", \n    z=\"pr\", \n    histfunc=\"sum\",\n    nbinsy=12,\n    color_continuous_scale=\"YlGnBu\",\n    range_color=(0, 75),\n)\nfig.show()\n</pre> In\u00a0[\u00a0]: Copied! <pre>## ADD CODE HERE\n</pre> ## ADD CODE HERE answer <pre>fig = px.scatter(\n    data_frame=gdf, \n    x=\"gndvi\", \n    y=\"DryYield\", \n    facet_col=\"Variety\", \n    opacity=0.25, \n    range_y=[0.1, 5], \n    range_x=[0.4, 0.9], \n    color=\"gndvi\",\n    color_continuous_scale=\"Greens\",\n    range_color=(0.4, 0.8),\n)\nfig.show()\n</pre> In\u00a0[\u00a0]: Copied! <pre>fig = px.colors.diverging.swatches_continuous()\nfig.show()\n</pre> fig = px.colors.diverging.swatches_continuous() fig.show() <p>We can use a diverging colour palette to visualise the same precipitation data. Monthly precipitation values are converted to z-scores, which represent deviations in monthly precipitation away from the mean. A z-score of zero represents average rainfall and can be used as the mid-point for a diverging colour palette. Here, we can use red-to-blue colour palette, with drier months represented by red shades.</p> In\u00a0[\u00a0]: Copied! <pre># compute average rainfall and standard deviation of rainfall to compute z scores\n# use z score as 0 for the mid-point of a diverging colour palette\navg_pr = precip_df[\"pr\"].mean()\nstd_pr = precip_df[\"pr\"].std()\nprecip_df.loc[:, \"z_score\"] = (precip_df.loc[:, \"pr\"] - avg_pr) / std_pr\n\nfig = px.density_heatmap(\n    precip_df,\n    x=\"year\", \n    y=\"month\", \n    z=\"z_score\", \n    histfunc=\"sum\",\n    nbinsy=12,\n    color_continuous_scale=\"RdBu\",\n    color_continuous_midpoint=0,\n)\nfig.show()\n</pre> # compute average rainfall and standard deviation of rainfall to compute z scores # use z score as 0 for the mid-point of a diverging colour palette avg_pr = precip_df[\"pr\"].mean() std_pr = precip_df[\"pr\"].std() precip_df.loc[:, \"z_score\"] = (precip_df.loc[:, \"pr\"] - avg_pr) / std_pr  fig = px.density_heatmap(     precip_df,     x=\"year\",      y=\"month\",      z=\"z_score\",      histfunc=\"sum\",     nbinsy=12,     color_continuous_scale=\"RdBu\",     color_continuous_midpoint=0, ) fig.show()"},{"location":"notebooks/week-2_1/#introduction-to-data-visualisation","title":"Introduction to data visualisation\u00b6","text":"<p>This lab will generate interactive visualisations of crop yield data for wheat and canola collected by a harvester from a field in Western Australia. This lab will provide an introduction to:</p> <ul> <li>interactive visualisations using Plotly Express</li> <li>using figures to represent and explore different features of a dataset</li> <li>using colour to visualise patterns in a dataset</li> </ul>"},{"location":"notebooks/week-2_1/#setup","title":"Setup\u00b6","text":""},{"location":"notebooks/week-2_1/#run-the-labs","title":"Run the labs\u00b6","text":"<p>You can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you're working with Google Colab be aware that your sessions are temporary and you'll need to take care to save, backup, and download your work.</p>"},{"location":"notebooks/week-2_1/#download-data","title":"Download data\u00b6","text":"<p>If you need to download the data for this lab, run the following code snippet.</p>"},{"location":"notebooks/week-2_1/#introduction","title":"Introduction\u00b6","text":""},{"location":"notebooks/week-2_1/#what-is-a-figure","title":"What is a figure?\u00b6","text":"<p>Data visualisation is the process of relating data values to elements of a figure on a computer display.</p> <p>The Grammar of Graphics is an underlying model that describes the mapping of data values to the visual elements of a figure. It provides a consistent framework for guiding us in how to take our data values and convert them into a figure that effectively represents the data and conveys the messages and insights we seek to communicate.</p> <p>In the Grammar of Graphics a plot comprises data and a mapping. The mapping (not cartographic here) is a formal description of how data values map onto elements of a figure. The elements of a figure are termed aesthetics and consist of:</p> <ul> <li>layers - geometric elements that represent data values such as points (e.g. for scatter plots), lines (e.g. for lines of best fit), and polyons (e.g. for histograms or bar plots).</li> <li>scales - relate data values to visual display properties such as colour (e.g. a blue to red colour palette for temperature), size (e.g. larger points for larger numbers), position (e.g. location on axes), or shapes (e.g. using triangles for group A and circles for group B). Scales are used to draw axes and legends for figures.</li> <li>coords - coordinate systems are used to map data values onto locations on the figure. On most 2D figures the x- and y-axes describe the coordinate space and on maps latitude and longitude describe the coordinate space (or you can use different coordinate reference systems).</li> <li>theme - the background styling of the figure such as fonts for labels and background colours.</li> </ul> <p></p> <p>Reading the A Layered Grammar of Graphics paper by Hadley Wickham provides a detailed description of the core concepts for designing high-quality data visualisations.</p>"},{"location":"notebooks/week-2_1/#interactive-visualisations","title":"Interactive visualisations\u00b6","text":"<p>Interactive visualisations are important tools for exploring complex and multidimensional data. They enable users to quickly develop an understanding of a dataset's structure and patterns by enabling them to interactively generate different views of the dataset.</p> <p>Generally, interactive visualisations are controlled by user input from mouse events (click, drag, hover), and, in response to mouse events, change what data and information is rendered on the computer display.</p> <p>Interactive visualisations are important tools for both exploratory analysis and for communicating the results of analysis to a wider audience. For exploratory analysis the quick feedback provided by interactive visualisations allows analysts to quickly build up an understanding of the datasets they are working with, spot noise or missing data, refine and develop hypotheses and research questions, and select suitable analytical and statistical tools for further work. Interactive visualisations are useful for communication as they enable active engagement with your datasets and the message you are conveying in a user friendly and non-technical manner.</p> <p>Here, we will be using Plotly Express to develop interactive visualisations. Plotly Express is a Python module that contains functions that convert data in Python programs into interactive visualisations that can be rendered in web browser based environments.</p> <p>Plotly Express has several useful features for developing interactive visualisations:</p> <ul> <li>functions to generate a range of figure types to explore spatial and non-spatial data (see the gallery)</li> <li>consistent API for functions used to generate the figures (i.e. if you learn the syntax and format to generate scatter plots it can be applied to generate histograms, density plots, bar plots, violin plots, web maps, etc.)</li> <li>simple and intuitive functions to generate the figures (i.e. produce complex interactive figures with a single line of code)</li> </ul>"},{"location":"notebooks/week-2_1/#import-modules","title":"Import modules\u00b6","text":""},{"location":"notebooks/week-2_1/#data-input","title":"Data input\u00b6","text":"<p>Let's read in some wheat and canola yield data collected by a harvester into a GeoPandas <code>GeoDataFrame</code>. The canola data corresponds to variety 43Y23 RR and the wheat data corresponds to variety ninja. We'll demonstrate how to create interactive visualisations using Plotly Express by generating a simple widget that displays the distribution of wheat and canola yields.</p>"},{"location":"notebooks/week-2_1/#interactive-visualisations-with-plotly-express","title":"Interactive visualisations with Plotly Express\u00b6","text":"<p>Now, let's unpick the syntax for specifying a Plotly Express visualisation. The functions to generate interactive figures are part of the plotly.express module which we've imported into our program as <code>px</code>.</p> <p><code>px.&lt;function name&gt;()</code> is how we'll access the function to generate a given figure. For example, to generate a histogram we call <code>px.histogram()</code> (if we wanted to generate a scatter plot we'd call <code>px.scatter()</code>, if we wanted to generate a line chart we'd call <code>px.line()</code>, if we wanted to generate a pie chart we'd call <code>px.pie()</code> - you get the pattern ...).</p> <p>Next, we need to pass data into the function that will be rendered on the computer display and specify arguments to map data values to elements on the figure. The Plotly Express documentation lists functions that can be used to generate figures and their parameters.</p> <p>Paramters for the <code>px.histogram()</code> function inclue:</p> <ul> <li><code>data_frame</code> - a <code>DataFrame</code> object containing the data to render on the histogram</li> <li><code>x</code> - specifies the column in the <code>DataFrame</code> to be mapped on the x-axis of the figure</li> <li><code>color</code> - a column whose values are used to assign colours to marks (elements) on the display</li> <li><code>marginal</code> - either violin, box, rug, or histogram that shows the distribution of the data</li> <li><code>hover_data</code> - list of column names with values that will be shown in a popup when the cursor hovers over a record on the display</li> </ul> <p>Use the Zoom tool to control what data is visualised and focus the figure on where most of the data is distributed.</p>"},{"location":"notebooks/week-2_1/#recap-quiz","title":"Recap quiz\u00b6","text":"<p>Look up the <code>range_x</code> paramter and consider how it could be used to remove the influence of outliers on the figure. Have a go at using it to restrict the range of values mapped to the x-axis.</p>"},{"location":"notebooks/week-2_1/#recap-quiz","title":"Recap quiz\u00b6","text":"<p>Can you limit the range of x-axis values to focus the figure on where most of the data is concentrated and remove the effect of outliers? (hint, you'll need to remove the <code>marginal_x</code> argument).</p>"},{"location":"notebooks/week-2_1/#adding-layers","title":"Adding layers\u00b6","text":"<p>The scatter plot we have generated above has layers of points for the scatter plot and layers of geometric elements for the box plot and violin plots. However, each of these layers are all rendered on their own sub-plot.</p> <p>There are often times when we want to overlay layers on the same plot. A common example of this is adding a trendline to a scatter plot to help the viewer see patterns and relationships in the data. If we refer back to the documentation for scatter plots we can see there is a <code>trendline</code> parameter. We can use this parameter to specify the kind of trendline we'd like to draw on our scatter plot:</p> <ul> <li><code>ols</code>: ordinary least squares (or linear line of best fit)</li> <li><code>loess</code>: locally weighted scatterplot smoothing line</li> <li><code>rolling</code>: rolling average or rolling median line</li> </ul> <p>Let's generate a scatter plot with a trendline to explore the relationship between the green normalised difference vegetation index (GNDVI, a satellite derived measure of vegetation greenness) and crop yield. Generally, higher maximum growing season GNDVI values are correlated with higher crop yields.</p> <p>If you hover your cursor over the trendline it will show you the equation for the trendline. You will also notice that we've used the the <code>range_x</code> and <code>range_y</code> parameters to focus the figure on the region where most of the data is concentrated and clip the outliers from the view.</p>"},{"location":"notebooks/week-2_1/#recap-quiz","title":"Recap quiz\u00b6","text":"Generally, it seems that maximum growing season GNDVI is higher for the wheat (Ninja) crop than canola (43Y23 RR). Can you think of an explanation for this? Canola canopies are characterised by yellow flowers which could reduce their greenness during the growing season."},{"location":"notebooks/week-2_1/#facets","title":"Facets\u00b6","text":"<p>So far we have distinguished groups of data points on the same figure by using a unique colour per-group. However, this can lead to cluttered figures which obscures important variation in the data. To avoid clutter we can create faceted figures where mutliple subplots of the same type are generated, which share axes, and different subsets (groups) of the data are rendered on each subplot.</p> <p>Wilke (2019) distinguish between faceted figures and compound figures. Compound figures are multiple figure types (e.g. scatter plots, histograms, maps), possibly of different datasets, combined into one figure. A key feature of a compound figure is that the subplots do not need to be arranged in a regular grid. The figures above with violin and box plots aligned on the margins of a scatter plot are examples of compound figures.</p> <p>In contrast, facet plots consist of subplots of the same type, showing subsets of the same dataset, and are arranged on a regular grid. You might see the term trellis or lattice plots used to describe facet plots. To ensure correct interpretation of faceted figures it is important that the axes on all plots share the same range and scalings.</p> <p>Let's create a faceted figure that shows the relationship between crop yield and the normalised difference yellowness index (NDYI) side-by-side. The NDYI is a spectral index computed from remote sensing data as a mathematical combination of green and blue reflectance values. Higher NDYI values are associated with a yellower land surface. The NDYI is often used to monitor canola flowering.</p> <p>We can use the <code>facet_row</code> parameter to align subplots on separate rows or the <code>facet_col</code> parameter to align the subplots on separate columns. We specify a column in our <code>GeoDataFrame</code> to use to create the facets. The dataset is split into subsets using unique values in the specified column and each subset is rendered on a subplot. Here, we pass in the <code>Variety</code> column to split the data by crop type.</p>"},{"location":"notebooks/week-2_1/#selecting-the-right-figure","title":"Selecting the \"right\" figure\u00b6","text":"<p>Chapter 5 of Wilke (2019) provides a directory of visualisations which serves as a useful guide for selecting the correct visualisation for different types of data.</p>"},{"location":"notebooks/week-2_1/#using-colour","title":"Using Colour\u00b6","text":"<p>A colour scale is used to map data values to colours on the display. Wilke (2019) outline three uses of colour on figures:</p> <ul> <li>colour to represent data values (e.g. using red shades for low precipitation and blue shades for high precipitation)</li> <li>colour to distinguish groups (e.g. using green for forest on a land cover map, blue for water, orange-red for desert, etc.)</li> <li>colour to highlight (e.g. using colour to highlight particular features on your visualisation)</li> </ul> <p>We can broadly characterise colour scales as being either continuous or qualitative.</p>"},{"location":"notebooks/week-2_1/#continuous-palettes","title":"Continuous palettes\u00b6","text":"<p>Continuous colour scales can be either sequential or diverging and are typically used when using colour to represent data values (often numeric continuous variables). Continuous colour scales can be used to visualise variation in attributes of vector geospatial data on chloropleth maps and variation in attributes of raster data as surfaces.</p>"},{"location":"notebooks/week-2_1/#sequential-palettes","title":"Sequential palettes\u00b6","text":"<p>A sequential colour scale is a palette which consists of single hue such as light green to dark green or light red to dark red. Multi-hue sequential colour scales often consist of hues that imply an intuitive and increasing order to the colours such as light yellows to dark red.</p> <p>Plotly express provides a range of inbuilt sequential colour scales:</p>"},{"location":"notebooks/week-2_1/#recap-quiz","title":"Recap quiz\u00b6","text":"<p>Can you create a heatmap of monthly precipitation over time using a <code>YlGnBu</code> colour palette?</p>"},{"location":"notebooks/week-2_1/#recap-quiz","title":"Recap quiz\u00b6","text":"<p>Using the <code>GeoDataFrame</code> <code>gdf</code> of crop yield values, can you create a scatter plot of crop yield (the <code>DryYield</code> column) and GNDVI (the <code>gndvi</code> column) and assign green shades to the points which reflect their GNDVI values? Tips: look up the <code>color</code>, <code>color_continuous_scale</code>, and <code>range_color</code> parameters of the <code>scatter()</code> function in the API docs.</p>"},{"location":"notebooks/week-2_1/#diverging-palettes","title":"Diverging palettes\u00b6","text":"<p>Diverging colour scales are used to represent data values deviating in two directions. Often a light colour (e.g. white) is used as the mid-point of a diverging colour scale with gradients of intensifying colour away from this mid-point. A common example of diverging colour scales are climate or weather anomalies where dry or hot years are represented with red colours and wet and cool years are represented with blue colours. Average conditions are often a pale red, pale blue, or white.</p> <p>Plotly also provides a range of diverging colour palettes we can use:</p>"},{"location":"notebooks/week-2_1/#qualitative-palettes","title":"Qualitative palettes\u00b6","text":"<p>Qualitative (or discrete) colour scales should be used to represent groups or categorical data (i.e. data where there is no logical ordering). Thus, qualitative colour scales should not represent gradients of light to dark or use colours that can be interpreted as having an implied ordering. Often, it is sensible to select colours that relate to the category (e.g. on land cover maps using green for vegetated categories, blue for water etc.).</p>"},{"location":"notebooks/week-2_2/","title":"Week 2 2","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport subprocess\n\nif \"data_lab-2_2\" not in os.listdir(os.getcwd()):\n    subprocess.run('wget \"https://github.com/geog3300-agri3003/lab-data/raw/main/data_lab-2_2.zip\"', shell=True, capture_output=True, text=True)\n    subprocess.run('unzip \"data_lab-2_2.zip\"', shell=True, capture_output=True, text=True)\n    if \"data_lab-2_2\" not in os.listdir(os.getcwd()):\n        print(\"Has a directory called data_lab-2_2 been downloaded and placed in your working directory? If not, try re-executing this code chunk\")\n    else:\n        print(\"Data download OK\")\n</pre> import os import subprocess  if \"data_lab-2_2\" not in os.listdir(os.getcwd()):     subprocess.run('wget \"https://github.com/geog3300-agri3003/lab-data/raw/main/data_lab-2_2.zip\"', shell=True, capture_output=True, text=True)     subprocess.run('unzip \"data_lab-2_2.zip\"', shell=True, capture_output=True, text=True)     if \"data_lab-2_2\" not in os.listdir(os.getcwd()):         print(\"Has a directory called data_lab-2_2 been downloaded and placed in your working directory? If not, try re-executing this code chunk\")     else:         print(\"Data download OK\") In\u00a0[\u00a0]: Copied! <pre>import os\n\nimport rioxarray as rxr\nimport xarray as xr\nimport plotly.express as px\nimport numpy as np\nimport geopandas as gpd\n</pre> import os  import rioxarray as rxr import xarray as xr import plotly.express as px import numpy as np import geopandas as gpd In\u00a0[\u00a0]: Copied! <pre>data_path = os.path.join(os.getcwd(), \"data_lab-2_2\")\n</pre> data_path = os.path.join(os.getcwd(), \"data_lab-2_2\") In\u00a0[\u00a0]: Copied! <pre># create a 2D ndarray\narr2d = np.array([[1, 2, 3], [4, 5, 6]])\narr2d\n</pre> # create a 2D ndarray arr2d = np.array([[1, 2, 3], [4, 5, 6]]) arr2d <p>The rank (or number of dimensions) of a <code>ndarray</code> is the number of axes.</p> In\u00a0[\u00a0]: Copied! <pre># the rank (ndim) of an ndarry is the number of axes \nprint(f\"the rank of the ndarray is {arr2d.ndim}\")\n</pre> # the rank (ndim) of an ndarry is the number of axes  print(f\"the rank of the ndarray is {arr2d.ndim}\") <p>The <code>shape</code> of an <code>ndarray</code> tells us the size of each axis (how many elements are arranged along that axis).</p> In\u00a0[\u00a0]: Copied! <pre># the shape of the ndarray \nprint(f\"the shape of the ndarray is {arr2d.shape}\")\n</pre> # the shape of the ndarray  print(f\"the shape of the ndarray is {arr2d.shape}\") <p><code>ndarray</code>s can be multidimensional. They can have more than two dimensions. Remote sensing images typically comprise multiple 2-dimensional arrays with each array corresponding to a raster of reflectance measured in a particular wavelength. This 3-dimensional raster data structure can be represented as a NumPy <code>ndarray</code> with the bands dimension on axis 0 (each band is a raster for a given wavelength), rows (height of each raster) on axis 1, and columns (width of each raster) on axis 2.</p> <p>Let's create a <code>ndarray</code> with 3-dimensions.</p> In\u00a0[\u00a0]: Copied! <pre># create a 3D ndarray\narr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\narr3d\n</pre> # create a 3D ndarray arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]) arr3d In\u00a0[\u00a0]: Copied! <pre>print(f\"the rank of the ndarray is {arr3d.ndim}\")\nprint(f\"the shape of the ndarray is {arr3d.shape}\")\n</pre> print(f\"the rank of the ndarray is {arr3d.ndim}\") print(f\"the shape of the ndarray is {arr3d.shape}\") <p>The concept of N-dimensional arrays can be extended further. For example, a 4-dimensional <code>ndarray</code> could store a sequence of 3-dimensional <code>ndarray</code>s where the fourth dimension is time and the object represents remote sensing images captured across multiple dates.</p> In\u00a0[\u00a0]: Copied! <pre>first_element = arr2d[0, 0]\nprint(first_element)\n</pre> first_element = arr2d[0, 0] print(first_element) <p>We can use the <code>:</code> symbol to specify slices of a NumPy <code>ndarray</code> to subset. For example, the following are three different ways of slicing the first two rows.</p> <p>Note that the slice is not inclusive of the index location after the <code>:</code> symbol. So, <code>arr2d[0:2, ]</code> would select the first two rows of <code>arr2d</code> - row 0 and row 1 (remember Python indexes from 0).</p> In\u00a0[\u00a0]: Copied! <pre>two_rows_1 = arr2d[0:2, ]\nprint(two_rows_1)\n\ntwo_rows_2 = arr2d[0:2]\nprint(two_rows_2)\n\ntwo_rows_3 = arr2d[:2]\nprint(two_rows_3)\n</pre> two_rows_1 = arr2d[0:2, ] print(two_rows_1)  two_rows_2 = arr2d[0:2] print(two_rows_2)  two_rows_3 = arr2d[:2] print(two_rows_3) <p>We can use multiple slices for different axes. For example, if we wanted to subset values from a selection of rows and columns.</p> In\u00a0[\u00a0]: Copied! <pre>two_rows_cols = arr2d[:2, 1:]\nprint(two_rows_cols)\n</pre> two_rows_cols = arr2d[:2, 1:] print(two_rows_cols) <p>It is important to remember that subsetting a NumPy <code>ndarray</code> using index locations and slicing only considers the location of elements within an array. You will need to consider and understand how locations within an array relate to \"real world\" dimensions such as geographic location or time.</p> In\u00a0[\u00a0]: Copied! <pre>s2_summer_path = os.path.join(data_path, \"week-2-s2-summer-2020.tif\")\nrds = rxr.open_rasterio(s2_summer_path)\n</pre> s2_summer_path = os.path.join(data_path, \"week-2-s2-summer-2020.tif\") rds = rxr.open_rasterio(s2_summer_path) <p>We have used <code>rioxarray</code> to read raster data stored in a GeoTIFF file into our program as an <code>xarray.DataArray</code> object referenced by the variable <code>rds</code>. We can print the <code>xarray.DataArray</code> object to inspect its metadata.</p> In\u00a0[\u00a0]: Copied! <pre>rds\n</pre> rds <p>The raster data stored in the GeoTIFF file is a satellite image of a field in the Wheatbelt. The data is captured by the Sentinel-2 satellite and it measures reflectance in many spectral bands (e.g. blue light, green light, red light, and near infrared light ...). This raster dataset has 23 bands, including some ancillary bands providing information about image quality and atmospheric conditions when the image was captured (we want to know if clouds are obscuring the satellite's view of the land surface).</p> <p>The attributes property of <code>rds</code> stores geospatial metadata such as the coordinate reference system (CRS) and the extent of the dataset. We can access this information via the <code>rds</code> object's <code>rio</code> accessor</p> In\u00a0[\u00a0]: Copied! <pre>print('CRS:', rds.rio.crs)\nprint('Resolution:', rds.rio.resolution())\nprint('Bounds:', rds.rio.bounds())\nprint('Width:', rds.rio.width)\nprint('Height:', rds.rio.height)\n</pre> print('CRS:', rds.rio.crs) print('Resolution:', rds.rio.resolution()) print('Bounds:', rds.rio.bounds()) print('Width:', rds.rio.width) print('Height:', rds.rio.height) <p>The raster data values are stored as arrays within the <code>xarray.DataArray</code> object and can be accessed via the <code>values</code> property.</p> In\u00a0[\u00a0]: Copied! <pre>arr = rds.values\nprint(f\"the shape of the array is {arr.shape}\")\narr\n</pre> arr = rds.values print(f\"the shape of the array is {arr.shape}\") arr <p>In subsequent labs we will explore <code>xarray</code> and raster data formats in more detail. For now, let's focus on visualising raster data stored in <code>xarray.DataArray</code> objects.</p> In\u00a0[\u00a0]: Copied! <pre>rds.sel(band=4).plot.imshow()\n</pre> rds.sel(band=4).plot.imshow() <p>The default visualisation using <code>plot.imshow()</code> returns a static image with <code>xarray.DataArray</code> labels and coordinates plotted. The default colour palette is viridis (yellow-green-blue shades). However, we can change this to a colour palette that relates to red reflectance using the <code>cmap</code> parameter of the <code>plot.imshow()</code> method. Let's use the <code>\"Reds\"</code> colour palette here.</p> In\u00a0[\u00a0]: Copied! <pre>rds.sel(band=4).plot.imshow(cmap=\"Reds\")\n</pre> rds.sel(band=4).plot.imshow(cmap=\"Reds\") In\u00a0[\u00a0]: Copied! <pre>## ADD CODE HERE\n</pre> ## ADD CODE HERE answer <pre>rds.sel(band=2).plot.imshow(cmap=\"Blues\")\n</pre> <p>The plots that you have generated so far have the <code>xarray.DataArray</code> labels attached to them (e.g. plot titles and all the band names listed by the colourbar). Can you look at the different parameters of the <code>plot.imshow()</code> and identify which parameter we can use to stop labels being rendered? Generate a plot of green reflectance (band 3) without labels and using the <code>\"Greens\"</code> colour palette.</p> In\u00a0[\u00a0]: Copied! <pre>## ADD CODE HERE\n</pre> ## ADD CODE HERE answer <p>Here, we need to use the <code>add_labels</code> parameter and pass in False as an argument.</p> <pre>rds.sel(band=3).plot.imshow(cmap=\"Greens\", add_labels=False)\n</pre> In\u00a0[\u00a0]: Copied! <pre>rds.sel(band=[4, 3, 2]).plot.imshow(vmin=0, vmax=0.4, add_labels=False)\n</pre> rds.sel(band=[4, 3, 2]).plot.imshow(vmin=0, vmax=0.4, add_labels=False) <p>Using the Plotly Express <code>imshow()</code> function we can create interactive visualisations of raster data stored in <code>xarray.DataArray</code> objects.</p> <p>The <code>px.imshow()</code> function takes in a 2D or 3D (for RGB images) NumPy <code>ndarray</code> as its first argument. The <code>values</code> of a <code>xarray.DataArray</code> are stored in NumPy <code>ndarray</code> objects, so we can select a band and pass it into <code>px.imshow()</code>. Let's visualise red band reflectance as an interactive image (hovering your cursor over the image will return a text popup with the red reflectance value at that location).</p> In\u00a0[\u00a0]: Copied! <pre>px.imshow(rds.sel(band=4).values)\n</pre> px.imshow(rds.sel(band=4).values) In\u00a0[\u00a0]: Copied! <pre>## ADD CODE HERE\n</pre> ## ADD CODE HERE answer <p>The <code>height</code> parameter lets you set the figure height in pixels.</p> <p>The <code>color_continuous_scale</code> parameter lets you set the colour palette.</p> <pre>px.imshow(rds.sel(band=4).values, color_continuous_scale=\"Reds\", height=500)\n</pre> In\u00a0[\u00a0]: Copied! <pre>s2_gndvi_path = os.path.join(data_path, \"gndvi_2020_bf66_fitted.tif\")\ngndvi_rds = rxr.open_rasterio(s2_gndvi_path)\n</pre> s2_gndvi_path = os.path.join(data_path, \"gndvi_2020_bf66_fitted.tif\") gndvi_rds = rxr.open_rasterio(s2_gndvi_path) In\u00a0[\u00a0]: Copied! <pre>gndvi_rds\n</pre> gndvi_rds <p>If we inspect the dataset, we can see that it has 52 bands. Each band is an array of GNDVI corresponding to a week of the year. In 2020, canola was grown in this field.</p> <p>In a previous lab we introduced the concept of a subplot. This is a good use case for a faceted figure. We can represent each week as a subplot, align the subplots sequentially through time, and use the same mapping of data values to colour to make comparisons of greenness across weeks easy.</p> <p>The <code>xarray.DataArray</code> <code>plot.imshow()</code> method has <code>col</code> and a <code>col_wrap</code> parameters. The <code>col</code> parameter can be passed a <code>dim</code> for which the faceted subplots are created. Passing in the <code>\"band\"</code> <code>dim</code> here will generate a separate image for each of the arrays along the dimension specified. Here, that will create a new GNDVI image for each week. The <code>col_wrap</code> parameter specifies how many images are laid out along one row on the display.</p> In\u00a0[\u00a0]: Copied! <pre>gndvi_rds.plot.imshow(col=\"band\", col_wrap=10)\n</pre> gndvi_rds.plot.imshow(col=\"band\", col_wrap=10) <p>You should be able to see the green up and green down dynamics of vegetative crop growth in this facet plot.</p> In\u00a0[\u00a0]: Copied! <pre>## ADD CODE HERE\n</pre> ## ADD CODE HERE answer <pre>s2_ndyi_path = os.path.join(data_path, \"ndyi_2020_bf66_fitted.tif\")\nndyi_rds = rxr.open_rasterio(s2_ndyi_path)\ngndvi_rds.plot.imshow(col=\"band\", col_wrap=10, cmap=\"afmhot\")\n</pre> In\u00a0[\u00a0]: Copied! <pre>elev_gdf_path = os.path.join(os.getcwd(), \"data_lab-2_2\", \"week-2-bf66-elevation.geojson\")\nelev_gdf = gpd.read_file(elev_gdf_path)\nelev_gdf.head()\n</pre> elev_gdf_path = os.path.join(os.getcwd(), \"data_lab-2_2\", \"week-2-bf66-elevation.geojson\") elev_gdf = gpd.read_file(elev_gdf_path) elev_gdf.head() <p>Printing out the <code>head()</code> of the <code>GeoDataFrame</code> <code>elev_gdf</code> clearly illustrates the tabular structure for representing vector data. Attributes are stored in columns, the locational information which is a <code>POINT</code> geometry object is stored in a <code>geometry</code> column, and each row corresponds to one geographic feature.</p> In\u00a0[\u00a0]: Copied! <pre>elev_gdf.explore()\n</pre> elev_gdf.explore() <p>This clearly shows the location of points within the field. However, it is not very informative about each point's elevation value. We can change the colour of each point to represent the variability in elevation across the field. To do this we need to use the <code>column</code> paramter of the <code>explore()</code> method to specify the column in the <code>GeoDataFrame</code> that we wish to represent using colour. We can also specifiy a colour palette to use with the <code>cmap</code> parameter.</p> <p>Executing the following code will render the elevation data with low elevations in blue shades and higher locations in yellow shades.</p> In\u00a0[\u00a0]: Copied! <pre>elev_gdf.explore(column=\"Elevation\", cmap=\"cividis\")\n</pre> elev_gdf.explore(column=\"Elevation\", cmap=\"cividis\") In\u00a0[\u00a0]: Copied! <pre>gdf_wheat_yield_2020 = gpd.read_file(os.path.join(data_path, \"fao_wheat_crop_yield_2020.geojson\"))\n</pre> gdf_wheat_yield_2020 = gpd.read_file(os.path.join(data_path, \"fao_wheat_crop_yield_2020.geojson\")) In\u00a0[\u00a0]: Copied! <pre>gdf_wheat_yield_2020.head()\n</pre> gdf_wheat_yield_2020.head() <p>We'll get a simple chloropleth map with the default viridis colour palette if we pass in the column label for wheat yield <code>\"yield_100g_ha\"</code> as an argument to the <code>column</code> parameter.</p> In\u00a0[\u00a0]: Copied! <pre>gdf_wheat_yield_2020.explore(column=\"yield_100g_ha\")\n</pre> gdf_wheat_yield_2020.explore(column=\"yield_100g_ha\") <p>You might find that the thick borders for country outlines obscures spotting spatial patterns and trends in wheat crop yields. Let's remove the borders. If you look at the docs for <code>explore()</code> you will see there is a <code>style_kwds</code> parameter we can pass a <code>dict</code> of styling configurations.</p> <p>A <code>dict</code> is a data structure with key:pairs. The <code>dict</code> passed to <code>style_kwds</code> contains a keys that descibe a visual element of the display we wish to adjust and a value that specifies how it should be adjusted. For example, the <code>stroke</code> key determines how the border of geometric features on the map is represented. We can set this to <code>False</code> to remove the border. Note, <code>dict</code> objects are specified by enclosing key:value pairs in braces <code>{}</code>.</p> <pre>{\"stroke\": False}\n</pre> In\u00a0[\u00a0]: Copied! <pre>gdf_wheat_yield_2020.explore(column=\"yield_100g_ha\", style_kwds={\"stroke\": False})\n</pre> gdf_wheat_yield_2020.explore(column=\"yield_100g_ha\", style_kwds={\"stroke\": False}) In\u00a0[\u00a0]: Copied! <pre>## ADD CODE HERE\n</pre> ## ADD CODE HERE answer <pre>gdf_wheat_yield_2020.explore(column=\"yield_100g_ha\", style_kwds={\"stroke\": False, \"fillOpacity\": 0.75})\n</pre> In\u00a0[\u00a0]: Copied! <pre>clum_carnarvon_path = os.path.join(data_path, \"clum_land_use_carnarvon.geojson\")\nclum_gdf = gpd.read_file(clum_carnarvon_path)\n</pre> clum_carnarvon_path = os.path.join(data_path, \"clum_land_use_carnarvon.geojson\") clum_gdf = gpd.read_file(clum_carnarvon_path) In\u00a0[\u00a0]: Copied! <pre>clum_gdf.head()\n</pre> clum_gdf.head() In\u00a0[\u00a0]: Copied! <pre>## ADD CODE HERE\n</pre> ## ADD CODE HERE answer <pre>clum_gdf.explore(column=\"Commod_dsc\", categorical=\"set2\")\n</pre>"},{"location":"notebooks/week-2_2/#geospatial-data-visualisation","title":"Geospatial data visualisation\u00b6","text":"<p>This lab will demonstrate how to generate exploratory and interactive visualisations of geospatial data including multispectral satellite images, point-based samples with in a field, global maps of crop yield, and crop types in orchards and plantations. This lab will provide an introduction to:</p> <ul> <li>raster and vector geospatial data</li> <li>generating interactive visualisations of vector datasets</li> <li>generating static and interactive visualisations of raster data</li> </ul> <p>This week the focus will be on quick, exploratory, and interactive visualisations of geospatial data. For a more detailed discussion of visualising geospatial data please read Wilke (2019). For a focus on generating cartographic quality static maps please see the open course Mapping and Data Visualization with Python.</p>"},{"location":"notebooks/week-2_2/#setup","title":"Setup\u00b6","text":""},{"location":"notebooks/week-2_2/#run-the-labs","title":"Run the labs\u00b6","text":"<p>You can run the labs locally on your machine or you can use cloud environments provided by Google Colab. If you're working with Google Colab be aware that your sessions are temporary and you'll need to take care to save, backup, and download your work.</p>"},{"location":"notebooks/week-2_2/#download-data","title":"Download data\u00b6","text":"<p>If you need to download the data for this lab, run the following code snippet.</p>"},{"location":"notebooks/week-2_2/#introduction-geospatial-data","title":"Introduction: Geospatial data\u00b6","text":"<p>Geospatial data represents geographic features or phenomenon as data in computer program or file.</p> <p>There are two main types of geospatial data:</p> <ul> <li>vector data - point, line, or polygon geometries</li> <li>raster data - images and arrays</li> </ul> <p>There are two components to geospatial data:</p> <ul> <li>Positional information describing location, shape, and extent (e.g. an <code>(x, y)</code> coordinate pair representing the location of a weather station)</li> <li>Attribute information describing characteristics of the phenomenon or entity (e.g. a name:value pair recording the name of the weather station <code>name:'Perth Airport'</code>)</li> </ul>"},{"location":"notebooks/week-2_2/#import-modules","title":"Import modules\u00b6","text":""},{"location":"notebooks/week-2_2/#raster-data-in-python","title":"Raster data in Python\u00b6","text":""},{"location":"notebooks/week-2_2/#raster-data-model","title":"Raster data model\u00b6","text":"<p>Raster data breaks the Earth's surface up into a grid of cells (pixels). Each pixel is assigned a value that corresponds to the geographic feature or phenomenon of interest. For example, pixels in a raster precipitation dataset would be assigned a numeric value that represents the amount of precipitation that fell at that location. Pixels in a land cover map would have an integer value that corresponds to a land cover class label. The values assigned to pixels in a raster dataset are the attribute information.</p> <p></p> <p>The size of the pixels relative to their position on the Earth's surface determines the spatial detail that can be resolved. A land cover map with pixels that represent a 1 km x 1 km portion of the Earth's surface will not be able to identify features such as individual buildings.</p> <p>The figure below shows the 2018 European Space Agency (ESA) Climate Change Initiative (CCI) land cover map. Each pixel represents a 300 m x 300 m area on the Earth\u2019s land surface and a pixel can only represent a single land cover type. If you look at the bottom two zoomed in maps you can see some limitations of representing land cover using 300 m x 300 m spatial resolution pixels. The shape of land cover features are poorly represented by the \u201cblock-like\u201d arrangement of pixels and there is variation in land cover within a single pixel (a mixed pixel problem).</p> <p></p> <p>Raster data represents geographic features and variables (e.g. elevation, reflectance in UAV images) as a grid of values (pixels). In Python, a data structure called an array is used to store and organise pixels in a raster dataset. Typically, NumPy <code>ndarray</code> objects are used for storing raster data in Python programs.</p>"},{"location":"notebooks/week-2_2/#arrays-numpy-ndarrays","title":"Arrays: NumPy <code>ndarray</code>s\u00b6","text":"<p>NumPy is a library used for scientific and numerical computing and is based around an N-dimensional <code>ndarray</code> object. An <code>ndarray</code> is a grid of elements of the same data type. The dimensions of a NumPy <code>ndarray</code> are called axes. NumPy <code>array</code>s can be created from sequences of values (e.g. stored in lists, tuples, other <code>ndarray</code>s).</p> <p></p> <p>We can create a simple 2-dimensional <code>ndarray</code> using the <code>array()</code> function. A <code>ndarray</code> with 2-dimensions is a matrix with rows arranged on the 0 axis and columns arranged on the 1 axis.</p>"},{"location":"notebooks/week-2_2/#subsetting-numpy-ndarrays","title":"Subsetting NumPy ndarrays\u00b6","text":"<p>A subsetting opertation is when you select values from a NumPy <code>ndarray</code> object based on their index locations. These operations are generally referred to as indexing and slicing when working with NumPy <code>ndarray</code> objects.</p> <p></p> <p>We can extract a value from a NumPy <code>ndarray</code> based on its index location. For example, the first element of a 2-Dimensional <code>ndarray</code> is at location <code>[0, 0]</code> (i.e. the 0th row and 0th column).</p>"},{"location":"notebooks/week-2_2/#xarray","title":"Xarray\u00b6","text":"<p>Xarray is a Python package that builds on top of NumPy's array-based data structures, but provides extra tools and functions that are useful for working with geospatial and Earth Science datasets. For example, <code>xarray.DataArray</code> data structures are objects that store multidimensional arrays of raster values and also store metadata information that describe the raster values.</p> <p><code>xarray</code> also provides convenient functions for reading raster data from geospatial data files on disk into memory as <code>xarray.DataArray</code> objects which we can use in our Python programs while retaining geographic and temporal information about the raster values stored in the array.</p> <p>Specifically, while a NumPy <code>ndarray</code> stores just the raster values and has some properties such as the <code>shape</code> (number of elements along each axis) and <code>ndim</code> (the dimensions of the array) it does not explicitly store any geospatial, temporal, or other geographic metadata. <code>xarray</code> solves this problem by reading raster data into an <code>xarray.DataArray</code> object with:</p> <ul> <li><code>values</code>: the multidimensional array of raster values</li> <li><code>dims</code>: a list of names for the dimensions of the array (e.g. instead axis 0 describing the 0th (row) dimension of an array that dimension can have a descriptive label such as longitude)</li> <li><code>coordinates</code>: a <code>list</code> of array-like objects that describe the location of an array element along that dimension (e.g. a 1D array of longitude values describing the location on the Earth's surface for each row in the array)</li> <li><code>attrs</code>: a <code>dict</code> of metadata attributes describing the dataset</li> </ul> <p><code>xarray.DataArray</code> objects can be stored within a larger container called <code>xarray.Dataset</code>. An <code>xarray.Dataset</code> can store many <code>xarray.DataArray</code> objects that share <code>dims</code> and <code>coordinates</code>. This is useful if you have different arrays of different <code>Variables</code> that correspond to the same locations and time-periods (e.g. you could have a separate array for temperature and precipitation values organised within a single <code>xarray.Dataset</code>).</p> <p></p> <p>Why is <code>xarray</code> useful for geospatial data?</p> <ul> <li>The <code>dims</code> and <code>coordinates</code> of an <code>xarray.DataArray</code> mean we can subset values from an array using latitude, longitude, time, or whatever a coordinate describes; we're not just restricted to subsetting values based on their index location within an array</li> <li><code>xarray.Dataset</code> objects provide a container to store multidimensional arrays (e.g. many variables and time points) that are common in geography, Earth Sciences, meteorology, and agriculture. For example, multispectral satellite images of the same location over time; arrays of different meteorological variables)</li> <li>useful functions for reading, analysing and visualising raster or array-like geospatial data that are common across many spatial data science workflows</li> </ul>"},{"location":"notebooks/week-2_2/#data-input","title":"Data input\u00b6","text":"<p>The <code>rioxarray</code> package provides tools for reading and writing raster geospatial data files into <code>xarray.DataArray</code> objects.</p> <p>Let's pass the path to a GeoTIFF file of raster data into the <code>rioxarray</code> <code>open_rasterio()</code> function:</p>"},{"location":"notebooks/week-2_2/#static-images","title":"Static images\u00b6","text":"<p><code>xarray.DataArray</code> objects have a <code>plot.imshow()</code> method that will render array based data as an image. Band 4 of the <code>xarray.DataArray</code> stores reflectance of red light off the Earth's surface. Let's plot it:</p>"},{"location":"notebooks/week-2_2/#recap-quiz","title":"Recap quiz\u00b6","text":"<p>The blue band (storing reflectance of blue light) in Sentinel-2 images is band 2 in the <code>xarray.DataArray</code> object referenced by <code>rds</code>. Can you plot blue band reflectance and select a sensible colour palette for visualing the spatial variation in blue reflectance?</p> <p>Hint: you can find a list of colour palettes here.</p>"},{"location":"notebooks/week-2_2/#colour-and-composite-images","title":"Colour and composite images\u00b6","text":"<p>A particular colour is defined by the intensity of light in different parts of the visible spectrum (e.g. yellow is a mixture of light in red and green wavelengths).</p> <p>Colour is represented by combinations (addition) of red, green, and blue light. Red, green, and blue are primary colours and combine to form white. An absence of red, green, and blue is black. Secondary colours can be formed by the addition of primary colours of varying intensities (e.g. yellow is the addition of red and green, magenta is the addition of red and blue, and cyan is the addition of green and blue).</p> <p>Computer displays consist of red, green, and blue sub-pixels, which when activated with different intensities, are perceived as different colours. The range of colours that can be displayed on a computer display is called the gamut. Colour in computer programs is represented as a three byte hexadecimal number with byte 1 corresponding to red, byte 2 corresponding to green, and byte 3 corresponding to blue. Each byte can take the range of 0 to 255 in decimal. 0 indicates the absence of a colour and 255 indicates saturation of that colour:</p> <ul> <li>white: 255 255 255</li> <li>black: 0 0 0</li> <li>red: 255 0 0</li> <li>green: 0 255 00</li> <li>blue: 0 0 255</li> </ul> <p></p> <p>Computer displays represent colour through varying the intensity of sub-pixel displays of red, green, and blue light. Variability in data values in multiband rasters can be visualised by relating data values in one band to the intensity of one of the primary colours on the computer display. Visualising a multiband raster in this way creates an additive RGB or colour composite image - it is called a composite image because each pixel is a composite of red, green, and blue light.</p> <p>Above we rendered the red, green, and blue band reflectance from the Sentinel-2 image separately. However, if we combine these reflectance measures into a composite image (e.g. where red reflectance is represented by sub-pixel intensity of red light) we can create a true colour image as if we were looking down on the Earth's surface with our eyes.</p> <p>We can select multiple bands from the <code>xarray.DataArray</code> object that correspond to red, green, and blue reflectance to render a true colour image. We need to pass a <code>list</code> of bands into the <code>sel()</code> method of the <code>xarray.DataArray</code> object referenced by the variable <code>rds</code>.</p>"},{"location":"notebooks/week-2_2/#interactive-raster-visualisations","title":"Interactive raster visualisations\u00b6","text":""},{"location":"notebooks/week-2_2/#recap-quiz","title":"Recap quiz\u00b6","text":"<p>Above, we have an interactive image of red band reflectance. However, the image is quite small and the colour palette could be more intuitive to indicate it's an image of red light reflectance. Can you look at the parameters in the <code>px.imshow()</code> docs that we could use to visualise reflectance using a red colour palette and increase the height of the plot?</p>"},{"location":"notebooks/week-2_2/#plotting-raster-time-series","title":"Plotting raster time series\u00b6","text":"<p>In many cases, we'll have raster data that covers the same location on the Earth's surface but is captured on different dates. A good example of this is remotely sensed satellite data which captures spectral reflectance data for the same location each time the satellite overpasses a location. In this instance, each band (or 2D array) might represent an observation for a variable on different dates. For example, green normalised difference vegetation index (GNDVI) values use green and near infrared reflectance to represent the greenness of a location. We can visualise GNDVI through time to represent vegetation growth dynamics (e.g. the green up of a crop after planting).</p> <p>Let's read in a raster dataset of GNDVI values for different dates.</p>"},{"location":"notebooks/week-2_2/#recap-quiz","title":"Recap quiz\u00b6","text":"<p>There is a GeoTIFF file <code>ndyi_2020_bf66_fitted.tif</code> in the <code>data_lab-2_2</code> folder. It stores normalised difference yellowness index (NDYI) values for each week of the year. Can you read this file into your program and plot each week's NDYI values as an image to visualise change in yellowness of the canola crop canopy through the growing season? Generate this figure as a faceted plot and select a suitable colour map to visualise change in yellowness.</p> <p>Hint: you can find a list of colour palettes here.</p>"},{"location":"notebooks/week-2_2/#vector-data-in-python","title":"Vector data in Python\u00b6","text":""},{"location":"notebooks/week-2_2/#vector-data-model","title":"Vector data model\u00b6","text":"<p>Vector data uses point, line, or polygon geometries to represent geographic features.</p> <p>Coordinate pairs: point locations or the vertices in lines and polygons are represented using coordinate pairs. The coordinate pairs indicate where that feature is located on the Earth's surface (relative to an origin); longitude and latitute are commonly used as coordinate pairs.</p> <p>Attribute information: vector data also stores non-spatial attribute information which describe characteristics of the geographic phenomenon or entity represented by the geometry feature.</p> <p></p>"},{"location":"notebooks/week-2_2/#geopandas-geodataframe","title":"GeoPandas GeoDataFrame\u00b6","text":"<p>A GeoPandas <code>GeoDataFrame</code> is a tabular data structure for storing vector geospatial data and is based on a regular pandas <code>DataFrame</code>.</p> <p>A <code>GeoDataFrame</code> consists of columns of non-spatial attributes similar to a pandas <code>DataFrame</code>. However, a <code>GeoDataFrame</code> also has a <code>geometry</code> column which is a <code>GeoSeries</code> of geometries for the spatial data associated with each row.</p> <p>In Python, geometries are represented as Shapely <code>Geometry</code> objects. The <code>geometry</code> column in a GeoPandas <code>GeoDataFrame</code> is a <code>Series</code> of Shapely <code>Geometry</code> objects. Printing a Shapely <code>Geometry</code> object returns a Well Known Text (WKT) string description of the geometry (e.g. <code>POINT (0, 1)</code>). The <code>geometry</code> column of a <code>GeoDataFrame</code> (or a <code>GeoSeries</code>) can be viewed as a sequence of Shapely <code>Geometry</code> objects:</p> <pre><code>a_geoseries = [POINT (0, 1), POINT (0, 2), POINT (2, 3)]\n</code></pre> <p>Shapely provides tools for representing geometries in Python programs. It does not provide tools for reading geometry data from disk or handling attribute data. GeoPandas <code>GeoDataFrame</code> and <code>GeoSeries</code> combine Shapely's functionality for handling geometries with tools for reading and writing vector data, handling attributes, and visualisation. Therefore, we will focus on using <code>GeoDataFrame</code>s in these labs.</p> <p>Let's read in a GeoJSON file storing the elevation of points sampled across the same field in Western Australia that we have been exploring using raster data.</p>"},{"location":"notebooks/week-2_2/#interactive-vector-visualisations","title":"Interactive vector visualisations\u00b6","text":"<p><code>GeoDataFrame</code>s have a helpful <code>explore()</code> method for rendering spatial data on a \"slippy\" web map.</p>"},{"location":"notebooks/week-2_2/#chloropleth-mapping","title":"Chloropleth mapping\u00b6","text":"<p>Chloropleth maps use a feature's fill colour to visualise spatial variation in a variable. A continuous colour palette is used to represent variation in the values of attributes of a vector spatial dataset. For a more detailed review of chloropleth maps please see Rey et al. (2020) and Wilke (2019).</p> <p>Let's create a chloropleth map of wheat crop yields at the national level in 2020 downloaded from FAOSTAT.</p>"},{"location":"notebooks/week-2_2/#recap-quiz","title":"Recap quiz\u00b6","text":"<p>The opacity of the fill colour on the chloropleth maps is set to 0.5. Can you find a parameter in the  <code>explore()</code> docs to change the <code>fillOpacity</code> to 0.75?</p> <p>Hint: you can use search tools and find tools to find words on the <code>explore()</code> docs page.</p>"},{"location":"notebooks/week-2_2/#categorical-vector-maps","title":"Categorical vector maps\u00b6","text":"<p>Sometimes the variable that we wish to visualise on a map using colour is not continuous but is categorical. An example could be the crop type associated with a polygon feature of field boundaries. In these cases we're mapping a categorical value to a colour and a change in colour does not represent an increase or decrease in a numeric value, but a change in group or class.</p> <p>In these cases qualitative (or discrete) colour scales should be used to represent groups (i.e. data where there is no logical ordering). Thus, qualitative colour scales should not represent gradients of light to dark or use colours that can be interpreted as having an implied ordering. Often, it is sensible to select colours that relate to the category (e.g. on land cover maps using green for vegetated categories, blue for water etc.).</p> <p>Let's make a categorical map of the crop type in a field for a selection of fields near Canarvon in Western Australia. The data is derived from the Catchment scale land use of Australia product.</p>"},{"location":"notebooks/week-2_2/#recap-quiz","title":"Recap quiz\u00b6","text":"<p>Can you make a categorical interactive map of the crop type for each field? You will need to use the <code>explore()</code> docs to identify which parameter to use to let <code>explore()</code> know it is visualising categorical data. You should pass in a qualitative colour palette as an argument to the this parameter. A list of qualitative colour palettes can be found here.</p>"}]}